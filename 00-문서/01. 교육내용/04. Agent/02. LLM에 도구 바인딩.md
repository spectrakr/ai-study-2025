
LLM 모델이 도구(tool) 를 호출할 수 있으려면 chat 요청을 할 때 모델에 도구 스키마(tool schema) 를 전달해야 한다.
  
도구 호출(tool calling) 기능을 지원하는 LangChain Chat Model 은 `.bind_tools()` 메서드를 구현하여 LangChain 도구 객체, Pydantic 클래스 또는 JSON 스키마 목록을 수신하고 공급자별 예상 형식으로 채팅 모델에 바인딩(binding) 한다.


### 1. 기본 실행 (도구 사용 X)

#### 실행
```python
llm.invoke("'enomix'의 글자수는 몇자야?")
```

#### 결과
```bash
AIMessage(content="'enomix'는 6글자입니다.", additional_kwargs={...})
```

일반적인 llm 호출시에는 AIMessage로 응답내용이 content에 포함되어 넘어온다.

### 2. 도구를 사용하여 실행

여기서 보는 코드는 좀 복잡해 보일 수 있는데, 도구를 실행하는 과정을 이해하기 위한 코드이다. 실제로 사용할 때는 아래 코드로 하지 않고 더 간단한 방법으로 실행한다. 복잡하지만 그 과정만 이해하도록 하자.

#### 실행
```python
@tool  
def get_word_length(word: str) -> int:  
    """Returns the length of a word."""  
    return len(word)

llm_with_tools = llm.bind_tools(tools)

llm_with_tools.invoke("'enomix'의 글자수는 몇자야?")
```
llm이 아닌 `bind_tools`로 도구와 같이 사용한다.

#### 결과
```bash
AIMessage(  
	content="",  
	additional_kwargs={  
		"tool_calls": [{  
			"id": "call_9xgjPuqjRI0AQ49JUCLoxPUE",  
			"function": {  
				"arguments": "{'word':'enomix'}", 
				"name": "get_word_length"
			}, "type": "function"  
		}],  
	"refusal": None  
},  
...
```
응답 내용에 LLM이 응답을 바로 하는 것이 아니라 도구호출을 하는 경우에는 content에는 공백으로 넘어오고 사용하는 도구가 tool_calls에 포함되어 넘어온다.

> AIMessage가 공백이고 tool_calls에 값이 넘어오면 AI 답변이 아니라고 도구를 호출해야 한다는 의미로 생각하면 된다.

#### tool_calls로 호출하면
```python
llm_with_tools.invoke("'enomix'의 글자수는 몇자야?").tool_calls
```

#### 결과
```json
[  
  {  
    "name": "get_word_length",  
    "args": {  
      "word": "enomix"  
    },  
    "id": "call_U2Hqlc76x35v8UJFnYWKqPY9",  
    "type": "tool_call"  
  }  
]
```

여기서 응답 포맷은 도구호출 포맷인데 도구 호출 전용 응답 파서인 JsonOutputToolParser()를 사용하여 chain을 만들어보자.
```python
chain = llm_with_tools | JsonOutputToolsParser(tools=tools)

tool_call_results = chain.invoke("'enomix'의 글자수는 몇자야?")
```

실행결과
```json
[  
  {  
    "args": {  
      "word": "dworks"  
    },  
    "type": "get_word_length"  
  }  
]
```

즉, 도구 호출은 `get_word_length` 함수를 실행하라는 의미고, 인수(args)로 `word=enomix`를 넘긴다는 의미이다.

우리가 원하는 결과는 get_word_length가 아니라 이 함수를 실행한 결과이다.
그래서 도구를 실행해주는 함수를 정의하고 실행하는 기능을 추가해보자.
```python
def execute_tool_calls(tool_call_results):  
    """  
    도구 호출 결과를 실행하는 함수  
    """    
    for tool_call_result in tool_call_results:  
        # 도구의 이름과 인자를 추출합니다.  
        tool_name = tool_call_result["type"]  # 도구의 이름(함수명)  
        tool_args = tool_call_result["args"]  # 도구에 전달되는 인자  
  
        # 도구 이름과 일치하는 도구를 찾아 실행합니다.  
        # next() 함수를 사용하여 일치하는 첫 번째 도구를 찾습니다.  
        matching_tool = next((tool for tool in tools if tool.name == tool_name), None)  
  
        if matching_tool:  
            # 일치하는 도구를 찾았다면 해당 도구를 실행합니다.  
            result = matching_tool.invoke(tool_args)  
            # 실행 결과를 출력합니다.  
            print(f"[실행도구] {tool_name} [Argument] {tool_args}\n[실행결과] {result}")  
        else:  
            # 일치하는 도구를 찾지 못했다면 경고 메시지를 출력합니다.  
            print(f"경고: {tool_name}에 해당하는 도구를 찾을 수 없습니다.")  
  
  
# 도구 호출 실행  
# 이전에 얻은 tool_call_results를 인자로 전달하여 함수를 실행합니다.  
execute_tool_calls(tool_call_results)
```

도구를 실행해주는 기능을 chain에 추가한다.
```python
chain = llm_with_tools | JsonOutputToolsParser(tools=tools) | execute_tool_calls
```


```python
chain.invoke("'enomix'의 글자수는 몇자야?")
```

실행결과
```bash
[실행도구] get_word_length [Argument] {'word': 'enomix'}
[실행결과] 6
```





