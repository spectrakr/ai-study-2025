
## 1. ollama 설치
https://ollama.com/

설치 후 재부팅이 필요할 수도 있다.

## 2. 모델 설치

#### 방법 1: ollama pull설치
- Ollama 공식 저장소에서 설치
- 장점
	- 명령어로 간단히 설치
	- 간단한 명령어로 업데이트 가능 - ollama pull <모델이름>
- 단점
	- Ollama에서 제공하는 모델만 가능
	- 네트워크 필요
	- Modelfile 설정 변경 불가

#### 방법 2: 모델 파일 직접 다운로드 & 설치
- 모델파일 (gguf) 다운로드 및 설치
- 장점
	- Hugging Face에 있는 모델 설치 가능
	- Modelfile 설정 변경 가능
	- 네트워크 불필요
- 단점
	- 설정 복잡할 수 있음
	- 모델 업데이트 시 다시 다운로드
	




## 3. 모델 파일 다운로드
 - EEVE
	 - 야놀자에서 라마2를 기반으로 한글이 잘되도록 튜닝을 한 모델
	 - 다운로드: https://huggingface.co/teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf/tree/main
- deepseek r1
	- DeepSeek-R1모델을 경량화하고 Qwen 기반으로 14B 파라미터 규모로 구현한 모델
	- 다운로드: https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-14B-GGUF/tree/main
	- https://wikidocs.net/274497
- 
- exaone 3.5
	- LG AI Research에서 개발한 AI 모델. 한국어, 영어를 잘하는 모델
	- 다운로드: https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct-GGUF/tree/main
	- https://wikidocs.net/274703

> **gguf란**
> 
> GGUF와 GGML은 GPT와 같은 언어 모델을 저장하기 위한 파일 형식이다.
> GGML은 조지 게르가노프가 개발한 머신 러닝을 위해 설계된 텐서 라이브러리로, Apple Silicon을 비롯한 다양한 하드웨어에서 대규모 모델과 고성능을 구현할 수 있도록 지원한다.
> 
> GGML은 GPT 모델을 위한 최초 파일형식이다.
> GGML은 여러 형식의 파일이 다수 존재한다. (즉 여러 파일을 다운로드 받아야 한다)
> GGUF는 하나의 파일로 작성되어 사용하기 용이하고 단일파일로 공유가 쉽다.


#### gguf 파일 다운로드

> gguf 파일 다운로드 (https://huggingface.co/teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf/tree/main)
저사양: EEVE-Korean-Instruct-10.8B-v1.0-Q4_0.gguf
괜찮은 사양: EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf





## 4. 템플릿 저장 (경로: models)
```bash
FROM EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf
TEMPLATE """{{- if .System }}
<s>{{ .System }}</s>
{{- end }}
<s>Human:
{{ .Prompt }}</s>
<s>Assistant:
"""

SYSTEM """A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions."""

PARAMETER stop <s>
PARAMETER stop </s>
```


## 5. 모델 생성

#### 해당 디렉토리로 이동
```bash
cd models
```

#### 모델파일 생성
```bash
ollama create EEVE-Korean-10.8B -f Modelfile
```

#### 생성결과 확인
```bash
NAME                           ID              SIZE      MODIFIED       
EEVE-Korean-10.8B:latest       d6109bf62021    11 GB     12 seconds ago 
```

#### 실행
```bash
ollama run EEVE-Korean-10.8B:latest
```

#### 질문
```bash
> 대한민국의 수도는?
```


#### 빠져나갈때
```bash
> /bye
```


#### 09-Ollama.ipynb로 실행
```python
llm = ChatOllama(model="EEVE-Korean-10.8B:latest")
```





### gemma:7b
```bash
ollama pull gemma:7b
```

### llava:7b
```bash
ollama pull llava:7b
```


## deepseek-r1

```bash
ollama pull deepseek-r1:7b
```


## exaone 3.5 7.8b
```bash
ollama pull exaone3.5:7.8b
```

