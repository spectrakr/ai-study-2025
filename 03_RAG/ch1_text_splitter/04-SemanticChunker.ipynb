{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00f269d",
   "metadata": {},
   "source": [
    "# SemanticChunker\n",
    "\n",
    "텍스트를 의미론적 유사성에 기반하여 분할합니다.\n",
    "\n",
    "**Reference**\n",
    "\n",
    "- [Greg Kamradt의 노트북](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "\n",
    "이 방법은 텍스트를 문장 단위로 분할한 후, 3개의 문장씩 그룹화하고, 임베딩 공간에서 유사한 문장들을 병합하는 과정을 거칩니다.\n",
    "\n",
    "> 의미적으로 유사한 내용을 모아주자.\n",
    "> \n",
    "> 어떤 청크는 길수도 있고, 어떤 것은 짧을 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b48cce",
   "metadata": {},
   "source": "샘플 텍스트를 로드하고 내용을 출력합니다.\n"
  },
  {
   "cell_type": "code",
   "id": "c170dd43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:37:50.280075Z",
     "start_time": "2025-03-17T05:37:50.275208Z"
    }
   },
   "source": [
    "# data/appendix-keywords.txt 파일을 열어서 f라는 파일 객체를 생성합니다.\n",
    "with open(\"./data/2025_사우회선출.txt\") as f:\n",
    "    file = f.read()  # 파일의 내용을 읽어서 file 변수에 저장합니다.\n",
    "\n",
    "# 파일으로부터 읽은 내용을 일부 출력합니다.\n",
    "print(file[:350])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 2024년 사우회입니다.\n",
      "어느덧 2024년이 마무리되어 가는 이 시점에 2025년 사우회를 이끌어주실 분에 대한 투표를 진행하겠습니다.\n",
      "모두 한 분 한 분의 소중한 한 표를 꼭 행사해 주시기 바랍니다!\n",
      "\n",
      "투표 방식: 무기명 온라인 1인 1투표\n",
      "투표 기간: 2024년 12월 23일(월)까지 (1주일간 진행)\n",
      "투표 링크: https://forms.gle/ooDQvUP4SzJRaUoS6\n",
      "\n",
      "[노사 협의회 구성원 및 선출 공고 사항]\n",
      "노사 협의회 구성원 중 근로자 대표는 노사 협의회장을 겸하며, 노사 간 중요 의사결정 과정에서 합의의 주체가 될 수 있습니다.\n",
      "다만, 제반 제도와 관련된 안내 및 직원 커뮤니케이션 등의\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e1817a14",
   "metadata": {},
   "source": [
    "## SemanticChunker 생성\n",
    "\n",
    "`SemanticChunker`는 LangChain의 실험적 기능 중 하나로, 텍스트를 의미론적으로 유사한 청크로 분할하는 역할을 합니다.\n",
    "\n",
    "이를 통해 텍스트 데이터를 보다 효과적으로 처리하고 분석할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b06b68b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:37:53.906795Z",
     "start_time": "2025-03-17T05:37:53.897856Z"
    }
   },
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "ab33ae70",
   "metadata": {},
   "source": [
    "`SemanticChunker`를 사용하여 텍스트를 의미적으로 관련된 청크로 분할합니다.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:37:56.698233Z",
     "start_time": "2025-03-17T05:37:55.949767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩을 사용하여 의미론적 청크 분할기를 초기화합니다.\n",
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), \n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=70\n",
    ")"
   ],
   "id": "6627b1dc9a4a094b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "dab515b0",
   "metadata": {},
   "source": [
    "## 텍스트 분할\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9b20b",
   "metadata": {},
   "source": [
    "- `text_splitter`를 사용하여 `file` 텍스트를 문서 단위로 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dfb5870d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:38:02.115604Z",
     "start_time": "2025-03-17T05:37:59.071145Z"
    }
   },
   "source": [
    "chunks = text_splitter.split_text(file)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "14a777bc",
   "metadata": {},
   "source": [
    "분할된 청크를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "eec69bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:38:04.748902Z",
     "start_time": "2025-03-17T05:38:04.741451Z"
    }
   },
   "source": [
    "# 분할된 청크 중 첫 번째 청크를 출력합니다.\n",
    "print(chunks[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 2024년 사우회입니다. 어느덧 2024년이 마무리되어 가는 이 시점에 2025년 사우회를 이끌어주실 분에 대한 투표를 진행하겠습니다.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8f03b26b",
   "metadata": {},
   "source": [
    "`create_documents()` 함수를 사용하여 청크를 문서로 변환할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fadaf823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T05:38:08.658932Z",
     "start_time": "2025-03-17T05:38:07.591875Z"
    }
   },
   "source": [
    "# text_splitter를 사용하여 분할합니다.\n",
    "docs = text_splitter.create_documents([file])\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"------ len: {len(doc.page_content)} -----\")\n",
    "    print(f\"{doc.page_content}\")# 분할된 문서 중 첫 번째 문서의 내용을 출력합니다."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ len: 82 -----\n",
      "안녕하세요, 2024년 사우회입니다. 어느덧 2024년이 마무리되어 가는 이 시점에 2025년 사우회를 이끌어주실 분에 대한 투표를 진행하겠습니다.\n",
      "------ len: 340 -----\n",
      "모두 한 분 한 분의 소중한 한 표를 꼭 행사해 주시기 바랍니다! 투표 방식: 무기명 온라인 1인 1투표\n",
      "투표 기간: 2024년 12월 23일(월)까지 (1주일간 진행)\n",
      "투표 링크: https://forms.gle/ooDQvUP4SzJRaUoS6\n",
      "\n",
      "[노사 협의회 구성원 및 선출 공고 사항]\n",
      "노사 협의회 구성원 중 근로자 대표는 노사 협의회장을 겸하며, 노사 간 중요 의사결정 과정에서 합의의 주체가 될 수 있습니다. 다만, 제반 제도와 관련된 안내 및 직원 커뮤니케이션 등의 업무는 여전히 인사팀에서 진행할 예정이오니, 근로자 대표로 선출된 직원분께서는 큰 부담 없이 선출 결과를 받아주시면 감사하겠습니다.\n",
      "------ len: 148 -----\n",
      "2025년 근로자(대표) 위원\n",
      "사우회장 1명, 총무 1명\n",
      "사용자 위원과 근로자 위원이 원활한 의사소통을 통해 상호 간의 이해와 협조를 증진함으로써 노사 공동의 이익을 구현합니다. 근로자 대표 (회사발전위원회)\n",
      "근로기준법상 각종 제도에 대해 사측과 합의를 진행합니다.\n",
      "------ len: 419 -----\n",
      "기존 사우회 및 회사발전위원회 위원장 선출 방식과 동일하게 근로자 투표 방식으로 진행됩니다. 단, 근로자 대표는 직원 과반수 이상의 동의를 얻어야 하므로, 선출된 후보자는 최다 추천을 받은 1인에 대해 근로자대표선임서를 통해 과반수 이상의 직원 서명 날인을 받아야 합니다. (오프라인 서명)\n",
      "후보 선출 기준\n",
      "\n",
      "근로자 대표 후보 (회사발전위원회)\n",
      "선출 기준: 역임자를 제외한 스펙트라 근속 10~15년 차 사우를 대상으로 선출. 사우회장 후보\n",
      "선출 기준: 역임자를 제외한 스펙트라 근속 5~9년 차 사우를 대상으로 선출. 주요 업무: 연중행사 및 사우 경조사(인사팀과 협업) 담당. 총무 후보\n",
      "선출 기준: 역임자를 제외한 스펙트라 근속 1~4년 차 사우를 대상으로 선출. 주요 업무:\n",
      "\n",
      "사우 경조사비 송금, 생일 축하금, 입사 축하금, 동호회비 송금.\n",
      "------ len: 20 -----\n",
      "지출 대장 작성 및 회장 업무 지원.\n",
      "------ len: 0 -----\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![semantic.png](./data/semantic.png)",
   "id": "a39d9579a6dede04"
  },
  {
   "cell_type": "markdown",
   "id": "1633cf8e",
   "metadata": {},
   "source": [
    "## Breakpoints\n",
    "\n",
    "이 chunker는 문장을 \"분리\"할 시점을 결정하여 작동합니다. 이는 두 문장 간의 임베딩 차이를 살펴봄으로써 이루어집니다.\n",
    "\n",
    "그 차이가 특정 임계값을 넘으면 문장이 분리됩니다.\n",
    "\n",
    "- 참고 영상: https://youtu.be/8OJC21T2SL4?si=PzUtNGYJ_KULq3-w&t=2580\n",
    "\n",
    "### Percentile\n",
    "\n",
    "기본적인 분리 방식은 백분위수(`Percentile`) 를 기반으로 합니다.\n",
    "\n",
    "이 방법에서는 문장 간의 모든 차이를 계산한 다음, 지정한 백분위수를 기준으로 분리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "744bbd95",
   "metadata": {},
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # OpenAI의 임베딩 모델을 사용하여 시맨틱 청커를 초기화합니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 분할 기준점 유형을 백분위수로 설정합니다.\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=70,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59aa8318",
   "metadata": {},
   "source": [
    "분할된 결과를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c7b3262",
   "metadata": {},
   "source": [
    "docs = text_splitter.create_documents([file])\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(doc.page_content)  # 분할된 문서 중 첫 번째 문서의 내용을 출력합니다.\n",
    "    print(\"===\" * 20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "07e83f74",
   "metadata": {},
   "source": [
    "`docs`의 길이를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "20c0cbd0",
   "metadata": {},
   "source": [
    "print(len(docs))  # docs의 길이를 출력합니다."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "21c1c9e8",
   "metadata": {},
   "source": [
    "### Standard Deviation\n",
    "\n",
    "이 방법에서는 지정한 `breakpoint_threshold_amount` 표준편차보다 큰 차이가 있는 경우 분할됩니다.\n",
    "\n",
    "- `breakpoint_threshold_type` 매개변수를 \"standard_deviation\"으로 설정하여 청크 분할 기준을 표준편차 기반으로 지정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "16a8d823",
   "metadata": {},
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # OpenAI의 임베딩 모델을 사용하여 시맨틱 청커를 초기화합니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 분할 기준으로 표준 편차를 사용합니다.\n",
    "    breakpoint_threshold_type=\"standard_deviation\",\n",
    "    breakpoint_threshold_amount=1.25,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "690db96c",
   "metadata": {},
   "source": [
    "분할된 결과를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1764de39",
   "metadata": {},
   "source": [
    "# text_splitter를 사용하여 분할합니다.\n",
    "docs = text_splitter.create_documents([file])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0743d8f6",
   "metadata": {},
   "source": [
    "docs = text_splitter.create_documents([file])\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(doc.page_content)  # 분할된 문서 중 첫 번째 문서의 내용을 출력합니다.\n",
    "    print(\"===\" * 20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "095170af",
   "metadata": {},
   "source": [
    "`docs`의 길이를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee9f46ad",
   "metadata": {},
   "source": [
    "print(len(docs))  # docs의 길이를 출력합니다."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c5b03d9b",
   "metadata": {},
   "source": [
    "### Interquartile\n",
    "\n",
    "이 방법에서는 사분위수 범위(interquartile range)를 사용하여 청크를 분할합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb408177",
   "metadata": {},
   "source": [
    "- `breakpoint_threshold_type` 매개변수를 \"interquartile\"로 설정하여 청크 분할 기준을 사분위수 범위로 지정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f32f5fe8",
   "metadata": {},
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # OpenAI의 임베딩 모델을 사용하여 의미론적 청크 분할기를 초기화합니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 분할 기준점 임계값 유형을 사분위수 범위로 설정합니다.\n",
    "    breakpoint_threshold_type=\"interquartile\",\n",
    "    breakpoint_threshold_amount=0.5,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12e0d2d6",
   "metadata": {},
   "source": [
    "# text_splitter를 사용하여 분할합니다.\n",
    "docs = text_splitter.create_documents([file])\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(doc.page_content)  # 분할된 문서 중 첫 번째 문서의 내용을 출력합니다.\n",
    "    print(\"===\" * 20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d186bb7",
   "metadata": {},
   "source": [
    "`docs`의 길이를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c693c11",
   "metadata": {},
   "source": [
    "print(len(docs))  # docs의 길이를 출력합니다."
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
