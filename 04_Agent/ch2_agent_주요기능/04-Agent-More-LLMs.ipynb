{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI ì™¸ ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸(Tool Calling Agent)\n",
    "\n",
    "OpenAI ì™¸ì—ë„ `Anthropic`, `Google Gemini`, `Together.ai`, `Ollama`, `Mistral`ê³¼ ê°™ì€ ë” ê´‘ë²”ìœ„í•œ ê³µê¸‰ì êµ¬í˜„ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆ ì±•í„°ì—ì„œëŠ” ë‹¤ì–‘í•œ LLM ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ í˜¸ì¶œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³  ë§í¬**\n",
    "\n",
    "- [LangChain ê³µì‹ ë„íë¨¼íŠ¸](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T04:18:27.741095Z",
     "start_time": "2025-04-07T04:18:27.726933Z"
    }
   },
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T04:18:28.759188Z",
     "start_time": "2025-04-07T04:18:28.276367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def get_current_time():\n",
    "    \"\"\"Use this to get current date or time\"\"\"\n",
    "    return datetime.now()\n",
    "\n",
    "@tool\n",
    "def search_dayoff(start_date: str, end_date: str) -> str:\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ë‚ ì§œì˜ íœ´ê°€ ì¼ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): ì‹œì‘ì¼, YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ (ì˜ˆ: 2024-01-01)\n",
    "        end_date (str): ì¢…ë£Œì¼, YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ (ì˜ˆ: 2024-01-01)\n",
    "\n",
    "    Returns:\n",
    "        str: í•´ë‹¹ ë‚ ì§œì˜ íœ´ê°€ ì¼ì • ì •ë³´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"http://172.16.120.203:9201/flex_dayoff_calendar/_search\"\n",
    "        body = {\"query\": {\"range\": {\"date\": {\"gte\": start_date, \"lte\": end_date}}}}\n",
    "        response = requests.post(url, json=body)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            hits = data.get(\"hits\", {}).get(\"hits\", [])\n",
    "            \n",
    "            if hits:\n",
    "                result = []\n",
    "                for hit in hits:\n",
    "                    source = hit.get(\"_source\", {})\n",
    "                    result.append(\n",
    "                        f\"[ë‚ ì§œ] {source.get('date', 'ì •ë³´ ì—†ìŒ')}\\n \"\n",
    "                        f\"[íœ´ê°€ì] {source.get('text', 'ì •ë³´ ì—†ìŒ')}, \"\n",
    "                    )\n",
    "                return \"\\n\".join(result)\n",
    "            else:\n",
    "                return f\"í•´ë‹¹í•˜ëŠ” íœ´ê°€ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        else:\n",
    "            return f\"API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}\"\n",
    "\n",
    "    except ValueError:\n",
    "        return \"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
    "    except Exception as e:\n",
    "        return f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T04:18:29.661850Z",
     "start_time": "2025-04-07T04:18:29.615134Z"
    }
   },
   "cell_type": "code",
   "source": "search_dayoff.invoke({\"start_date\": \"2025-03-31\", \"end_date\": \"2025-03-31\"})",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ë‚ ì§œ] 2025-03-31\\n [íœ´ê°€ì] ['ğŸŒ´ [ì •ì§€í›ˆ] íœ´ê°€', 'ğŸŒ´ [ì •ì€ì˜] íœ´ê°€', 'ğŸŒ´ [ê¹€ì§€í›ˆ] íœ´ê°€', 'ğŸŒ´ [ê¹€ê±´ìš°] íœ´ê°€ - 3:30\\\\u202fPM ~ 5:30\\\\u202fPM', 'ğŸŒ´ [ì œì€ë¹„] íœ´ê°€'], \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T04:18:32.813793Z",
     "start_time": "2025-04-07T04:18:32.811678Z"
    }
   },
   "source": [
    "# tools ì •ì˜\n",
    "tools = [get_current_time, search_dayoff]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "\n",
    "- `chat_history` : ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ (ë©€í‹°í„´ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ìƒëµ ê°€ëŠ¥í•©ë‹ˆë‹¤.)\n",
    "- `agent_scratchpad` : ì—ì´ì „íŠ¸ê°€ ì„ì‹œë¡œ ì €ì¥í•˜ëŠ” ë³€ìˆ˜\n",
    "- `input` : ì‚¬ìš©ìì˜ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# í”„ë¡¬í”„íŠ¸ëŠ” ì—ì´ì „íŠ¸ì—ê²Œ ëª¨ë¸ì´ ìˆ˜í–‰í•  ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. (ë„êµ¬ì˜ ì´ë¦„ê³¼ ì—­í• ì„ ì…ë ¥)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"use the `get_current_time` tool to find out today's date.\"\n",
    "            \"Make sure to use the `search_dayoff` tool for searching ì—°ì°¨, íœ´ê°€.\"\n",
    "            \"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calling ì„ ì§€ì›í•˜ëŠ” ë‹¤ì–‘í•œ LLM ëª©ë¡\n",
    "\n",
    "ì‹¤ìŠµ ì§„í–‰ì„ ìœ„í•´ì„œëŠ” ì•„ë˜ ë‚´ìš©ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**Anthropic**\n",
    "\n",
    "- [Anthropic API í‚¤ ë°œê¸‰ ê´€ë ¨](https://console.anthropic.com/settings/keys)\n",
    "- `.env` íŒŒì¼ ë‚´ `ANTHROPIC_API_KEY` ì— ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”\n",
    "\n",
    "**Gemini**\n",
    "\n",
    "- [Gemini API í‚¤ ë°œê¸‰ ê´€ë ¨](https://aistudio.google.com/app/apikey?hl=ko)\n",
    "- `.env` íŒŒì¼ ë‚´ `GOOGLE_API_KEY` ì— ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”\n",
    "\n",
    "**Together AI**\n",
    "\n",
    "- [Together AI API í‚¤ ë°œê¸‰ ê´€ë ¨](https://api.together.ai/)\n",
    "- `.env` íŒŒì¼ ë‚´ `TOGETHER_API_KEY` ì— ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”\n",
    "\n",
    "**Ollama**\n",
    "\n",
    "- [Ollama Tool Calling ì§€ì› ëª¨ë¸ ë¦¬ìŠ¤íŠ¸](https://ollama.com/search?c=tools)\n",
    "- [ì´ë²ˆ ì‹¤ìŠµì— ì‚¬ìš©í•  llama3.1 ëª¨ë¸](https://ollama.com/library/llama3.1)\n",
    "- í„°ë¯¸ë„ ì°½ì— `ollama pull llama3.1` ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤.\n",
    "- ì´ì „ì— Ollama ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ë©´, [Ollama](https://wikidocs.net/233805) ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain-ollama ì„¤ì¹˜ë¥¼ í•œ ë’¤ ì§„í–‰í•´ ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# !pip install -qU langchain-ollama==0.1.3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "# GPT-4o-mini\n",
    "gpt = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Claude-3-5-sonnet\n",
    "claude = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n",
    "\n",
    "# Gemini-1.5-pro-latest\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "\n",
    "# Llama-3.1-70B-Instruct-Turbo\n",
    "llama = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    ")\n",
    "\n",
    "gemma3 = ChatOllama(model=\"gemma-3:latest\", temperature=0)\n",
    "\n",
    "qwen = ChatOllama(model=\"qwen-2.5:latest\") \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llama_gpt = ChatOpenAI(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    base_url=\"https://gqei2ikplhhuvm-8000.proxy.runpod.net/v1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_with_llama = llama_gpt.bind_tools(tools)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_with_llama.invoke(\"ì˜¤ëŠ˜ì€ ëª‡ì¼ì¸ê°€ìš”?\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM ê¸°ë°˜ìœ¼ë¡œ Agent ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# Agent ìƒì„±\n",
    "gpt_agent = create_tool_calling_agent(gpt, tools, prompt)\n",
    "claude_agent = create_tool_calling_agent(claude, tools, prompt)\n",
    "gemini_agent = create_tool_calling_agent(gemini, tools, prompt)\n",
    "llama_agent = create_tool_calling_agent(llama, tools, prompt)\n",
    "gemma_agent = create_tool_calling_agent(gemma3, tools, prompt)\n",
    "qwen_agent = create_tool_calling_agent(qwen, tools, prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgentExecutor ìƒì„± í›„ ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# gpt_agent ì‹¤í–‰\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=gpt_agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "# result = agent_executor.invoke({\"input\": \"ì˜¤ëŠ˜ íœ´ê°€ì ëˆ„êµ¬ì•¼?\"})\n",
    "result = agent_executor.invoke({\"input\": \"What day is it today?\"})\n",
    "# result = agent_executor.invoke({\"input\": \"ì´ë²ˆì£¼ íœ´ê°€ì ëª¨ë‘ ë§í•´ì¤˜\"})\n",
    "\n",
    "print(\"Agent ì‹¤í–‰ ê²°ê³¼:\")\n",
    "print(result[\"output\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ì–‘í•œ llmì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒì€ ì…ë ¥ë°›ì€ llmì„ ì‚¬ìš©í•˜ì—¬ Agent ë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def execute_agent(llm, tools, input_text, label):\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "    result = executor.invoke({\"input\": input_text})\n",
    "    print(f\"[{label}] ê²°ê³¼ì…ë‹ˆë‹¤.\")\n",
    "    if isinstance(result[\"output\"], list) and len(result[\"output\"]) > 0:\n",
    "        for item in result[\"output\"]:\n",
    "            if \"text\" in item:\n",
    "                print(item[\"text\"])\n",
    "    elif isinstance(result[\"output\"], str):\n",
    "        print(result[\"output\"])\n",
    "    else:\n",
    "        print(result[\"output\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê° llm ë³„ë¡œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "query = (\n",
    "    \"ì˜¤ëŠ˜ íœ´ê°€ì ëˆ„êµ¬ì•¼?\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:48:31.858926Z",
     "start_time": "2025-04-07T01:48:27.024268Z"
    }
   },
   "source": [
    "# gpt\n",
    "execute_agent(gpt, tools, query, \"gpt\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt] ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "ì˜¤ëŠ˜ íœ´ê°€ìëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "- ğŸŒ´ ì •ì§€í›ˆ íœ´ê°€\n",
      "- ğŸŒ´ ë¬¸ìŠ¹ë§Œ íœ´ê°€ (2:00 PM ~ 5:00 PM)\n",
      "- ğŸŒ´ ê¹€ê±´ìš° íœ´ê°€ (1:00 PM ~ 5:00 PM)\n",
      "- ğŸŒ´ ì´ì„ ì˜ íœ´ê°€\n",
      "- ğŸŒ´ ì²œìŠ¹ë¯¼ íœ´ê°€ (9:00 AM ~ 2:00 PM)\n",
      "- ğŸŒ´ ê¹€ì§€í›ˆ íœ´ê°€ (9:00 AM ~ 2:00 PM)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:46:12.080379Z",
     "start_time": "2025-04-07T01:46:04.244550Z"
    }
   },
   "source": [
    "# claude\n",
    "execute_agent(claude, tools, query, \"claude\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[claude] ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "ì˜¤ëŠ˜(2025ë…„ 4ì›” 7ì¼)ì˜ íœ´ê°€ì ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. ì •ì§€í›ˆ: ì¢…ì¼ íœ´ê°€\n",
      "2. ë¬¸ìŠ¹ë§Œ: ì˜¤í›„ 2ì‹œë¶€í„° 5ì‹œê¹Œì§€ íœ´ê°€\n",
      "3. ê¹€ê±´ìš°: ì˜¤í›„ 1ì‹œë¶€í„° 5ì‹œê¹Œì§€ íœ´ê°€\n",
      "4. ì´ì„ ì˜: ì¢…ì¼ íœ´ê°€\n",
      "5. ì²œìŠ¹ë¯¼: ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 2ì‹œê¹Œì§€ íœ´ê°€\n",
      "6. ê¹€ì§€í›ˆ: ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 2ì‹œê¹Œì§€ íœ´ê°€\n",
      "\n",
      "ì´ 6ëª…ì˜ ì§ì›ì´ ì˜¤ëŠ˜ íœ´ê°€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì •ì§€í›ˆë‹˜ê³¼ ì´ì„ ì˜ë‹˜ì€ ì¢…ì¼ íœ´ê°€ì´ë©°, ë‚˜ë¨¸ì§€ ë¶„ë“¤ì€ ë¶€ë¶„ íœ´ê°€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:46:25.215118Z",
     "start_time": "2025-04-07T01:46:21.153375Z"
    }
   },
   "source": [
    "# gemini\n",
    "execute_agent(gemini, tools, query, \"gemini\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gemini] ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "ì˜¤ëŠ˜ (2025ë…„ 4ì›” 7ì¼) íœ´ê°€ìëŠ” ì •ì§€í›ˆ, ë¬¸ìŠ¹ë§Œ(ì˜¤í›„ 2ì‹œ~5ì‹œ), ê¹€ê±´ìš°(ì˜¤í›„ 1ì‹œ~5ì‹œ), ì´ì„ ì˜, ì²œìŠ¹ë¯¼(ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 2ì‹œ), ê¹€ì§€í›ˆ(ì˜¤ì „ 9ì‹œ~ì˜¤í›„ 2ì‹œ)ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:46:29.754875Z",
     "start_time": "2025-04-07T01:46:28.539242Z"
    }
   },
   "source": [
    "# llama3.1 70B (Together.ai)\n",
    "execute_agent(\n",
    "    llama,\n",
    "    tools,\n",
    "    query,\n",
    "    \"llama3.1 70B\",\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[llama3.1 70B] ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "name\": \"search_dayoff\", \"parameters\": {\"start_date\": \"get_current_time\", \"end_date\": \"get_current_time\"}}\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:48:13.582537Z",
     "start_time": "2025-04-07T01:46:44.252515Z"
    }
   },
   "source": [
    "# gemma3 (ollama)\n",
    "execute_agent(gemma3, tools, query, \"gemma3\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gemma3] ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "ì˜¤ëŠ˜(2025ë…„ 4ì›” 7ì¼) íœ´ê°€ìëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: ì •ì§€í›ˆ, ë¬¸ìŠ¹ë§Œ(ì˜¤í›„ 2ì‹œë¶€í„° ì˜¤í›„ 5ì‹œê¹Œì§€), ê¹€ê±´ìš°(ì˜¤í›„ 1ì‹œë¶€í„° ì˜¤í›„ 5ì‹œê¹Œì§€), ì´ì„ ì˜, ì²œìŠ¹ë¯¼(ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 2ì‹œê¹Œì§€), ê¹€ì§€í›ˆ(ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 2ì‹œê¹Œì§€).<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T01:48:18.581479Z",
     "start_time": "2025-04-07T01:48:16.957538Z"
    }
   },
   "source": [
    "# qwen2.5 7B (ollama)\n",
    "execute_agent(qwen, tools, query, \"qwen2.5(Ollama)\")"
   ],
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "registry.ollama.ai/library/qwen-2.5:latest does not support tools (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mResponseError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# qwen2.5 7B (ollama)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mexecute_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mqwen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mqwen2.5(Ollama)\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mexecute_agent\u001B[39m\u001B[34m(llm, tools, input_text, label)\u001B[39m\n\u001B[32m      2\u001B[39m agent = create_tool_calling_agent(llm, tools, prompt)\n\u001B[32m      3\u001B[39m executor = AgentExecutor(agent=agent, tools=tools, verbose=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m result = \u001B[43mexecutor\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_text\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m] ê²°ê³¼ì…ë‹ˆë‹¤.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result[\u001B[33m\"\u001B[39m\u001B[33moutput\u001B[39m\u001B[33m\"\u001B[39m], \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(result[\u001B[33m\"\u001B[39m\u001B[33moutput\u001B[39m\u001B[33m\"\u001B[39m]) > \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/chains/base.py:170\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    169\u001B[39m     run_manager.on_chain_error(e)\n\u001B[32m--> \u001B[39m\u001B[32m170\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    171\u001B[39m run_manager.on_chain_end(outputs)\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/chains/base.py:160\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    157\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    158\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_inputs(inputs)\n\u001B[32m    159\u001B[39m     outputs = (\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    162\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call(inputs)\n\u001B[32m    163\u001B[39m     )\n\u001B[32m    165\u001B[39m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] = \u001B[38;5;28mself\u001B[39m.prep_outputs(\n\u001B[32m    166\u001B[39m         inputs, outputs, return_only_outputs\n\u001B[32m    167\u001B[39m     )\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1624\u001B[39m, in \u001B[36mAgentExecutor._call\u001B[39m\u001B[34m(self, inputs, run_manager)\u001B[39m\n\u001B[32m   1622\u001B[39m \u001B[38;5;66;03m# We now enter the agent loop (until it returns something).\u001B[39;00m\n\u001B[32m   1623\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m._should_continue(iterations, time_elapsed):\n\u001B[32m-> \u001B[39m\u001B[32m1624\u001B[39m     next_step_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_take_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1625\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1626\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1627\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1628\u001B[39m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1629\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1630\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1631\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(next_step_output, AgentFinish):\n\u001B[32m   1632\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._return(\n\u001B[32m   1633\u001B[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001B[32m   1634\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1330\u001B[39m, in \u001B[36mAgentExecutor._take_next_step\u001B[39m\u001B[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[39m\n\u001B[32m   1321\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_take_next_step\u001B[39m(\n\u001B[32m   1322\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1323\u001B[39m     name_to_tool_map: Dict[\u001B[38;5;28mstr\u001B[39m, BaseTool],\n\u001B[32m   (...)\u001B[39m\u001B[32m   1327\u001B[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1328\u001B[39m ) -> Union[AgentFinish, List[Tuple[AgentAction, \u001B[38;5;28mstr\u001B[39m]]]:\n\u001B[32m   1329\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._consume_next_step(\n\u001B[32m-> \u001B[39m\u001B[32m1330\u001B[39m         \u001B[43m[\u001B[49m\n\u001B[32m   1331\u001B[39m \u001B[43m            \u001B[49m\u001B[43ma\u001B[49m\n\u001B[32m   1332\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1333\u001B[39m \u001B[43m                \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1334\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1335\u001B[39m \u001B[43m                \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1336\u001B[39m \u001B[43m                \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1337\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1338\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1339\u001B[39m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m   1340\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1330\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m   1321\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_take_next_step\u001B[39m(\n\u001B[32m   1322\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1323\u001B[39m     name_to_tool_map: Dict[\u001B[38;5;28mstr\u001B[39m, BaseTool],\n\u001B[32m   (...)\u001B[39m\u001B[32m   1327\u001B[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1328\u001B[39m ) -> Union[AgentFinish, List[Tuple[AgentAction, \u001B[38;5;28mstr\u001B[39m]]]:\n\u001B[32m   1329\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._consume_next_step(\n\u001B[32m-> \u001B[39m\u001B[32m1330\u001B[39m         \u001B[43m[\u001B[49m\n\u001B[32m   1331\u001B[39m \u001B[43m            \u001B[49m\u001B[43ma\u001B[49m\n\u001B[32m   1332\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1333\u001B[39m \u001B[43m                \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1334\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1335\u001B[39m \u001B[43m                \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1336\u001B[39m \u001B[43m                \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1337\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1338\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1339\u001B[39m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m   1340\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/agents/agent.py:1358\u001B[39m, in \u001B[36mAgentExecutor._iter_next_step\u001B[39m\u001B[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[39m\n\u001B[32m   1355\u001B[39m     intermediate_steps = \u001B[38;5;28mself\u001B[39m._prepare_intermediate_steps(intermediate_steps)\n\u001B[32m   1357\u001B[39m     \u001B[38;5;66;03m# Call the LLM to see what to do.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1358\u001B[39m     output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_action_agent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mplan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1359\u001B[39m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1360\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1361\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1362\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1363\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m OutputParserException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1364\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.handle_parsing_errors, \u001B[38;5;28mbool\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain/agents/agent.py:581\u001B[39m, in \u001B[36mRunnableMultiActionAgent.plan\u001B[39m\u001B[34m(self, intermediate_steps, callbacks, **kwargs)\u001B[39m\n\u001B[32m    573\u001B[39m final_output: Any = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    574\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stream_runnable:\n\u001B[32m    575\u001B[39m     \u001B[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001B[39;00m\n\u001B[32m    576\u001B[39m     \u001B[38;5;66;03m# streaming\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m     \u001B[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001B[39;00m\n\u001B[32m    580\u001B[39m     \u001B[38;5;66;03m# accumulate the output into final output and return that.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrunnable\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    582\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfinal_output\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfinal_output\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:3414\u001B[39m, in \u001B[36mRunnableSequence.stream\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3408\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstream\u001B[39m(\n\u001B[32m   3409\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   3410\u001B[39m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[32m   3411\u001B[39m     config: Optional[RunnableConfig] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   3412\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   3413\u001B[39m ) -> Iterator[Output]:\n\u001B[32m-> \u001B[39m\u001B[32m3414\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:3401\u001B[39m, in \u001B[36mRunnableSequence.transform\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3395\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtransform\u001B[39m(\n\u001B[32m   3396\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   3397\u001B[39m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[32m   3398\u001B[39m     config: Optional[RunnableConfig] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   3399\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   3400\u001B[39m ) -> Iterator[Output]:\n\u001B[32m-> \u001B[39m\u001B[32m3401\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._transform_stream_with_config(\n\u001B[32m   3402\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   3403\u001B[39m         \u001B[38;5;28mself\u001B[39m._transform,\n\u001B[32m   3404\u001B[39m         patch_config(config, run_name=(config \u001B[38;5;129;01mor\u001B[39;00m {}).get(\u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.name),\n\u001B[32m   3405\u001B[39m         **kwargs,\n\u001B[32m   3406\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2201\u001B[39m, in \u001B[36mRunnable._transform_stream_with_config\u001B[39m\u001B[34m(self, input, transformer, config, run_type, **kwargs)\u001B[39m\n\u001B[32m   2199\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2200\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2201\u001B[39m         chunk: Output = context.run(\u001B[38;5;28mnext\u001B[39m, iterator)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m   2202\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[32m   2203\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:3364\u001B[39m, in \u001B[36mRunnableSequence._transform\u001B[39m\u001B[34m(self, input, run_manager, config, **kwargs)\u001B[39m\n\u001B[32m   3361\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3362\u001B[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001B[32m-> \u001B[39m\u001B[32m3364\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m final_pipeline\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1414\u001B[39m, in \u001B[36mRunnable.transform\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   1411\u001B[39m final: Input\n\u001B[32m   1412\u001B[39m got_first_val = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1414\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[32m   1415\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001B[39;49;00m\n\u001B[32m   1416\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# then call stream.\u001B[39;49;00m\n\u001B[32m   1417\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001B[39;49;00m\n\u001B[32m   1418\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# the `+` operator.\u001B[39;49;00m\n\u001B[32m   1419\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001B[39;49;00m\n\u001B[32m   1420\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# only operate on the last chunk,\u001B[39;49;00m\n\u001B[32m   1421\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001B[39;49;00m\n\u001B[32m   1422\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgot_first_val\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1423\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfinal\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:5572\u001B[39m, in \u001B[36mRunnableBindingBase.transform\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5566\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtransform\u001B[39m(\n\u001B[32m   5567\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   5568\u001B[39m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[32m   5569\u001B[39m     config: Optional[RunnableConfig] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   5570\u001B[39m     **kwargs: Any,\n\u001B[32m   5571\u001B[39m ) -> Iterator[Output]:\n\u001B[32m-> \u001B[39m\u001B[32m5572\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.bound.transform(\n\u001B[32m   5573\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   5574\u001B[39m         \u001B[38;5;28mself\u001B[39m._merge_configs(config),\n\u001B[32m   5575\u001B[39m         **{**\u001B[38;5;28mself\u001B[39m.kwargs, **kwargs},\n\u001B[32m   5576\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1432\u001B[39m, in \u001B[36mRunnable.transform\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   1429\u001B[39m             final = ichunk\n\u001B[32m   1431\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[32m-> \u001B[39m\u001B[32m1432\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stream(final, config, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:428\u001B[39m, in \u001B[36mBaseChatModel.stream\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    425\u001B[39m     \u001B[38;5;28mself\u001B[39m.rate_limiter.acquire(blocking=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    427\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m428\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m    430\u001B[39m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun-\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mrun_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_ollama/chat_models.py:722\u001B[39m, in \u001B[36mChatOllama._stream\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    715\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_stream\u001B[39m(\n\u001B[32m    716\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    717\u001B[39m     messages: List[BaseMessage],\n\u001B[32m   (...)\u001B[39m\u001B[32m    720\u001B[39m     **kwargs: Any,\n\u001B[32m    721\u001B[39m ) -> Iterator[ChatGenerationChunk]:\n\u001B[32m--> \u001B[39m\u001B[32m722\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_chat_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    723\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    724\u001B[39m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mChatGenerationChunk\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m=\u001B[49m\u001B[43mAIMessageChunk\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    726\u001B[39m \u001B[43m                    \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   (...)\u001B[39m\u001B[32m    739\u001B[39m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    740\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/langchain_ollama/chat_models.py:589\u001B[39m, in \u001B[36mChatOllama._create_chat_stream\u001B[39m\u001B[34m(self, messages, stop, **kwargs)\u001B[39m\n\u001B[32m    586\u001B[39m chat_params = \u001B[38;5;28mself\u001B[39m._chat_params(messages, stop, **kwargs)\n\u001B[32m    588\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chat_params[\u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m589\u001B[39m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.chat(**chat_params)\n\u001B[32m    590\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    591\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.chat(**chat_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-uLcZw9jp-py3.11/lib/python3.11/site-packages/ollama/_client.py:168\u001B[39m, in \u001B[36mClient._request.<locals>.inner\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    166\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m httpx.HTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    167\u001B[39m   e.response.read()\n\u001B[32m--> \u001B[39m\u001B[32m168\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e.response.text, e.response.status_code) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    170\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m r.iter_lines():\n\u001B[32m    171\u001B[39m   part = json.loads(line)\n",
      "\u001B[31mResponseError\u001B[39m: registry.ollama.ai/library/qwen-2.5:latest does not support tools (status code: 400)"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
