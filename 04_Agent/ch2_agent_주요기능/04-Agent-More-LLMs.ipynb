{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 외 도구 호출 에이전트(Tool Calling Agent)\n",
    "\n",
    "OpenAI 외에도 `Anthropic`, `Google Gemini`, `Together.ai`, `Ollama`, `Mistral`과 같은 더 광범위한 공급자 구현을 지원합니다.\n",
    "\n",
    "이번 챕터에서는 다양한 LLM 을 사용하여 도구 호출 에이전트를 생성하고 실행하는 방법을 살펴보겠습니다.\n",
    "\n",
    "**참고 링크**\n",
    "\n",
    "- [LangChain 공식 도큐먼트](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# 도구 정의\n",
    "@tool\n",
    "def get_current_time():\n",
    "    \"\"\"Use this to get current date or time\"\"\"\n",
    "    return datetime.now()\n",
    "\n",
    "@tool\n",
    "def search_dayoff(start_date: str, end_date: str) -> str:\n",
    "    \"\"\"\n",
    "    특정 날짜의 휴가 일정을 조회합니다.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): 시작일, YYYY-MM-DD 형식의 날짜 (예: 2024-01-01)\n",
    "        end_date (str): 종료일, YYYY-MM-DD 형식의 날짜 (예: 2024-01-01)\n",
    "\n",
    "    Returns:\n",
    "        str: 해당 날짜의 휴가 일정 정보\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"http://172.16.120.203:9201/flex_dayoff_calendar/_search\"\n",
    "        body = {\"query\": {\"range\": {\"date\": {\"gte\": start_date, \"lte\": end_date}}}}\n",
    "        response = requests.post(url, json=body)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            hits = data.get(\"hits\", {}).get(\"hits\", [])\n",
    "            \n",
    "            if hits:\n",
    "                result = []\n",
    "                for hit in hits:\n",
    "                    source = hit.get(\"_source\", {})\n",
    "                    result.append(\n",
    "                        f\"[날짜] {source.get('date', '정보 없음')}\\n \"\n",
    "                        f\"[휴가자] {source.get('text', '정보 없음')}, \"\n",
    "                    )\n",
    "                return \"\\n\".join(result)\n",
    "            else:\n",
    "                return f\"해당하는 휴가 일정이 없습니다.\"\n",
    "        else:\n",
    "            return f\"API 호출 실패: HTTP {response.status_code}\"\n",
    "\n",
    "    except ValueError:\n",
    "        return \"잘못된 날짜 형식입니다. YYYY-MM-DD 형식으로 입력해주세요.\"\n",
    "    except Exception as e:\n",
    "        return f\"오류가 발생했습니다: {str(e)}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "search_dayoff.invoke({\"start_date\": \"2025-03-31\", \"end_date\": \"2025-03-31\"})",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# tools 정의\n",
    "tools = [get_current_time, search_dayoff]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 용 프롬프트 생성\n",
    "\n",
    "- `chat_history` : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\n",
    "- `agent_scratchpad` : 에이전트가 임시로 저장하는 변수\n",
    "- `input` : 사용자의 입력"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 프롬프트 생성\n",
    "# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"use the `get_current_time` tool to find out today's date.\"\n",
    "            \"Make sure to use the `search_dayoff` tool for searching 연차, 휴가.\"\n",
    "            \"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calling 을 지원하는 다양한 LLM 목록\n",
    "\n",
    "실습 진행을 위해서는 아래 내용을 설정해야 합니다.\n",
    "\n",
    "**Anthropic**\n",
    "\n",
    "- [Anthropic API 키 발급 관련](https://console.anthropic.com/settings/keys)\n",
    "- `.env` 파일 내 `ANTHROPIC_API_KEY` 에 발급받은 키를 설정하세요\n",
    "\n",
    "**Gemini**\n",
    "\n",
    "- [Gemini API 키 발급 관련](https://aistudio.google.com/app/apikey?hl=ko)\n",
    "- `.env` 파일 내 `GOOGLE_API_KEY` 에 발급받은 키를 설정하세요\n",
    "\n",
    "**Together AI**\n",
    "\n",
    "- [Together AI API 키 발급 관련](https://api.together.ai/)\n",
    "- `.env` 파일 내 `TOGETHER_API_KEY` 에 발급받은 키를 설정하세요\n",
    "\n",
    "**Ollama**\n",
    "\n",
    "- [Ollama Tool Calling 지원 모델 리스트](https://ollama.com/search?c=tools)\n",
    "- [이번 실습에 사용할 llama3.1 모델](https://ollama.com/library/llama3.1)\n",
    "- 터미널 창에 `ollama pull llama3.1` 명령어를 입력하여 모델을 다운로드 받습니다.\n",
    "- 이전에 Ollama 를 사용하지 않았다면, [Ollama](https://wikidocs.net/233805) 를 참고해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain-ollama 설치를 한 뒤 진행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# !pip install -qU langchain-ollama==0.1.3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "# GPT-4o-mini\n",
    "gpt = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Claude-3-5-sonnet\n",
    "claude = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n",
    "\n",
    "# Gemini-1.5-pro-latest\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "\n",
    "# Llama-3.1-70B-Instruct-Turbo\n",
    "llama = ChatOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    ")\n",
    "\n",
    "gemma3 = ChatOllama(model=\"gemma-3:latest\", temperature=0)\n",
    "\n",
    "qwen = ChatOllama(model=\"qwen-2.5:latest\") \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 기반으로 Agent 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# Agent 생성\n",
    "gpt_agent = create_tool_calling_agent(gpt, tools, prompt)\n",
    "claude_agent = create_tool_calling_agent(claude, tools, prompt)\n",
    "gemini_agent = create_tool_calling_agent(gemini, tools, prompt)\n",
    "llama_agent = create_tool_calling_agent(llama, tools, prompt)\n",
    "gemma_agent = create_tool_calling_agent(gemma3, tools, prompt)\n",
    "qwen_agent = create_tool_calling_agent(qwen, tools, prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AgentExecutor 생성 후 실행 및 결과 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# gpt_agent 실행\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=gpt_agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "result = agent_executor.invoke({\"input\": \"오늘 휴가자 누구야?\"})\n",
    "# result = agent_executor.invoke({\"input\": \"이번주 휴가자 모두 말해줘\"})\n",
    "\n",
    "print(\"Agent 실행 결과:\")\n",
    "print(result[\"output\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 llm을 사용하여 에이전트를 실행합니다.\n",
    "\n",
    "다음은 입력받은 llm을 사용하여 Agent 를 생성하고 실행하여 결과를 출력하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def execute_agent(llm, tools, input_text, label):\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "    result = executor.invoke({\"input\": input_text})\n",
    "    print(f\"[{label}] 결과입니다.\")\n",
    "    if isinstance(result[\"output\"], list) and len(result[\"output\"]) > 0:\n",
    "        for item in result[\"output\"]:\n",
    "            if \"text\" in item:\n",
    "                print(item[\"text\"])\n",
    "    elif isinstance(result[\"output\"], str):\n",
    "        print(result[\"output\"])\n",
    "    else:\n",
    "        print(result[\"output\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 llm 별로 에이전트를 생성하고 실행하여 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "query = (\n",
    "    \"오늘 휴가자 누구야?\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# gpt\n",
    "execute_agent(gpt, tools, query, \"gpt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# claude\n",
    "execute_agent(claude, tools, query, \"claude\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# gemini\n",
    "execute_agent(gemini, tools, query, \"gemini\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# llama3.1 70B (Together.ai)\n",
    "execute_agent(\n",
    "    llama,\n",
    "    tools,\n",
    "    query,\n",
    "    \"llama3.1 70B\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# gemma3 (ollama)\n",
    "execute_agent(gemma3, tools, query, \"gemma3\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# qwen2.5 7B (ollama)\n",
    "execute_agent(qwen, tools, query, \"qwen2.5(Ollama)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
