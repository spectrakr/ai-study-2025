{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# Adaptive RAG\n",
    "\n",
    "이 튜토리얼은 Adaptive RAG(Adaptive Retrieval-Augmented Generation)의 구현을 다룹니다. \n",
    "\n",
    "Adaptive RAG는 쿼리 분석과 능동적/자기 수정 RAG를 결합하여 다양한 데이터 소스에서 정보를 검색하고 생성하는 전략입니다. \n",
    "\n",
    "이 튜토리얼에서는 LangGraph를 사용하여 웹 검색과 자기 수정 RAG 간의 라우팅을 구현합니다.\n",
    "\n",
    "**주로 다루는 내용**\n",
    "\n",
    "- **Create Index**: 인덱스 생성 및 문서 로드\n",
    "- **LLMs**: LLM을 사용한 쿼리 라우팅 및 문서 평가\n",
    "- **Web Search Tool**: 웹 검색 도구 설정\n",
    "- **Construct the Graph**: 그래프 상태 및 흐름 정의\n",
    "- **Compile Graph**: 그래프 컴파일 및 워크플로우 구축\n",
    "- **Use Graph**: 그래프 실행 및 결과 확인\n",
    "\n",
    "----\n",
    "\n",
    "**Adaptive RAG**는 **RAG**의 전략으로, (1) [쿼리 분석](https://blog.langchain.dev/query-construction/)과 (2) [Self-Reflective RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)을 결합합니다.\n",
    "\n",
    "[논문: Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) 에서는 쿼리 분석을 통해 다음과 같은 라우팅을 수행합니다.\n",
    "\n",
    "- `No Retrieval`\n",
    "- `Single-shot RAG`\n",
    "- `Iterative RAG`\n",
    "\n",
    "LangGraph를 사용하여 이를 구현합니다.\n",
    "\n",
    "이 구현에서는 다음과 같은 라우팅을 수행합니다.\n",
    "\n",
    "- **웹 검색**: 최신 이벤트와 관련된 질문에 사용\n",
    "- **자기 수정 RAG**: 인덱스와 관련된 질문에 사용\n",
    "\n",
    "![adaptive-rag.png](./assets/langgraph-adaptive-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb73bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25ec196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T11:12:51.539233Z",
     "start_time": "2025-04-09T11:12:51.521051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {},
   "source": [
    "## 기본 PDF 기반 Retrieval Chain 생성\n",
    "\n",
    "여기서는 PDF 문서를 기반으로 Retrieval Chain 을 생성합니다. 가장 단순한 구조의 Retrieval Chain 입니다.\n",
    "\n",
    "단, LangGraph 에서는 Retirever 와 Chain 을 따로 생성합니다. 그래야 각 노드별로 세부 처리를 할 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이전 튜토리얼에서 다룬 내용이므로, 자세한 설명은 생략합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cb77da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T11:13:01.089164Z",
     "start_time": "2025-04-09T11:12:54.405230Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "loader = PDFPlumberLoader(\"data/2024_프로야구_리그규정_요약.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = loader.load()\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = Chroma.from_documents(documents=split_docs, embedding=embeddings)\n",
    "\n",
    "pdf_retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fc536",
   "metadata": {},
   "source": [
    "## 쿼리 라우팅과 문서 평가\n",
    "\n",
    "**LLMs** 단계에서는 **쿼리 라우팅**과 **문서 평가**를 수행합니다. 이 과정은 **Adaptive RAG**의 중요한 부분으로, 효율적인 정보 검색과 생성에 기여합니다.\n",
    "\n",
    "- **쿼리 라우팅**: 사용자의 쿼리를 분석하여 적절한 정보 소스로 라우팅합니다. 이를 통해 쿼리의 목적에 맞는 최적의 검색 경로를 설정할 수 있습니다.\n",
    "- **문서 평가**: 검색된 문서의 품질과 관련성을 평가하여 최종 결과의 정확성을 높입니다. 이 과정은 **LLMs**의 성능을 극대화하는 데 필수적입니다.\n",
    "\n",
    "이 단계는 **Adaptive RAG**의 핵심 기능을 지원하며, 정확하고 신뢰할 수 있는 정보 제공을 목표로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b78d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# 최신 LLM 모델 이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# 사용자 쿼리를 가장 관련성 높은 데이터 소스로 라우팅하는 데이터 모델\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # 데이터 소스 선택을 위한 리터럴 타입 필드\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to 프로야구 리그규정.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "\n",
    "# Routing 을 위한 프롬프트 템플릿 생성\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 라우터를 결합하여 질문 라우터 생성\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4d831",
   "metadata": {},
   "source": [
    "다음은 쿼리 라우팅 결과를 테스트 해본 뒤 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0874c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색이 필요한 질문\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"야구 현역선수등록은 몇명이야?\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d22b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "source": [
    "# 웹 검색이 필요한 질문\n",
    "print(question_router.invoke({\"question\": \"판교에서 가장 맛있는 딤섬집 찾아줘\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc43b99",
   "metadata": {},
   "source": [
    "### 검색 평가기(Retrieval Grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1221d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# 문서 평가를 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 검색결과 평가기 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cac10",
   "metadata": {},
   "source": [
    "생성한 `retrieval_grader` 를 사용하여 문서 검색결과를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa5e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질문 설정\n",
    "question = \"각 구단은 몇 경기씩 해?\"\n",
    "\n",
    "# 질문에 대한 관련 문서 검색\n",
    "docs = pdf_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "055e5e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============0============\n",
      "서 전체 전적 다승, 해당 구단간 경기에서 전체 다득점, 전년도\n",
      "성적순으로 순위를 결정한다.\n",
      "단, KBO 정규시즌 제6, 7, 8, 9, 10위가 2개 구단 이상일 경우\n",
      "에는 승률로 순위를 결정하되, 승률이 동일할 경우 공동 순위\n",
      "로 한다. 문서상 표기, 개막전 편성, KBO 신인 드래프트 등\n",
      "순서를 필요로 하는 경우에는 해당 구단간 전체 전적 다승, 해\n",
      "당 구단간 전체 다득점, 전년도 성적 순위로 순서를 정한다.\n",
      "(2020.1.10 ➜ 2022.3.29 개정)\n",
      "제4조 경기규칙\n",
      "KBO가 주최하는 모든 경기는 공식야구규칙에 따른다.\n",
      "제5조 경기일정 결정 및 변경\n",
      "1. 우천 및 기타 사유로 예정된 경기를 거행하지 못했을 경우 총\n",
      "재가 추후 결정하며 연기된 경기는 필요한 경우 월요일 경기,\n",
      "더블헤더를 거행할 수 있다.\n",
      "단, 더블헤더 제1경기는 9회까지로 한다.\n",
      "2. 지상파 중계로 인해 시간을 변경할 경우에는 홈구단이 결정하\n",
      "여 KBO에 통보한다. 지상파 중계로 인한 시간 변경 요청이 있\n",
      "----------------------------------------------------------------------------------------------------\n",
      "============1============\n",
      "경기출장을 금지한다.\n",
      "제16조 경기사용구와 관리\n",
      "1. 경기사용구는 KBO가 선정한 경기사용구를 사용한다.\n",
      "2. KBO는 경기사용구를 월 1회 구입하여 각 구단에 공급한다. 각\n",
      "구단 경기사용구 담당자는 경기개시 1시간 전에 심판위원에게\n",
      "이를 전달하고 심판위원은 봉인해제 및 공 상태를 점검한 이후\n",
      "에 경기에 사용한다. 구단에 경기사용구가 전달된 이후에는 구\n",
      "단 담당자가 경기사용구의 관리 책임을 맡는다.\n",
      "10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "============2============\n",
      "제1장 KBO 정규시즌\n",
      "제1조 경기방식\n",
      "1. 단일 리그제로 각 구단은 144경기(구단간 16차전)씩\n",
      "총 720경기를 거행한다.\n",
      "2. 연장전은 12회(KBO 포스트시즌 15회)까지로 하고 승패를\n",
      "가리지 못할 경우에는 무승부로 한다.\n",
      "제2조 승률계산법\n",
      "승률은 승수/(승수＋패수)로 한다.\n",
      "제3조 연도 구단순위 및 기록\n",
      "1. 연도 구단순위는 KBO 한국시리즈 우승구단이 제1위, 준우승\n",
      "구단이 제2위, 그 이하는 KBO 정규시즌 승률순으로 한다.\n",
      "2. KBO 한국시리즈, KBO 플레이오프, KBO 준플레이오프, KBO\n",
      "와일드카드 결정전, 정규시즌 1위 결정전의 기록은 KBO 정규\n",
      "시즌의 기록에 가산하지 않고 별도 취급한다.\n",
      "3. KBO 정규시즌 제2, 3, 4위가 2개 구단 또는 3개 구단 이상일\n",
      "경우에는 해당 구단간 경기에서 전체 전적 다승, 해당 구단간\n",
      "경기에서 전체 다득점, 전년도 성적순으로 순위를 결정한다.\n",
      "정규시즌 제1, 5위가 2개 구단일 경우에는 와일드카드 결정전\n",
      "----------------------------------------------------------------------------------------------------\n",
      "============3============\n",
      "3. 봉인해제 후 경기 중 사용하지 않은 경기사용구는 경기종료 후\n",
      "심판위원이 별도로 봉인하여 다음 경기에 사용할 수 있도록 한다.\n",
      "제17조 구단기 게양\n",
      "홈구단은 전 구단기를 상비하여 경기가 행하여지는 당일 양 구단\n",
      "기를 게양하여야 한다.\n",
      "전년도 우승구단은 구단기와 소정의 우승기를 함께 게양하여야\n",
      "한다.\n",
      "제18조 입장요금\n",
      "입장요금은 각 구단이 자율적으로 결정하여 시행한다.\n",
      "제19조 응원시 금지사항\n",
      "구장 내의 관객석에서 앰프(AMP)를 사용하는 등 과도한 응원 행\n",
      "위로 관객에게 불쾌감을 주거나 경기에 지장을 줄 경우 주심은 경\n",
      "기관리인에게 응원 행위의 중지를 요청할 수 있다.\n",
      "제20조 경기중지에 따른 입장요금 처리\n",
      "1. 노게임이 선고되었을 때 동일구장의 다음 경기에 입장할 수 있\n",
      "도록 한다.\n",
      "2. 정식경기(서스펜디드 경기 포함) 또는 정식 무승부 경기가 되\n",
      "었을 때 전액 징수한다.\n",
      "11\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"============{i}============\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef397b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "# 검색된 문서의 내용 가져오기\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce41bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링 하는 코드 예시\n",
    "filtered_docs = []\n",
    "for doc in docs:\n",
    "    result = retrieval_grader.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content,\n",
    "        }\n",
    "    )\n",
    "    if result.binary_score == \"yes\":\n",
    "        filtered_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20f9275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제1장 KBO 정규시즌\n",
      "제1조 경기방식\n",
      "1. 단일 리그제로 각 구단은 144경기(구단간 16차전)씩\n",
      "총 720경기를 거행한다.\n",
      "2. 연장전은 12회(KBO 포스트시즌 15회)까지로 하고 승패를\n",
      "가리지 못할 경우에는 무승부로 한다.\n",
      "제2조 승률계산법\n",
      "승률은 승수/(승수＋패수)로 한다.\n",
      "제3조 연도 구단순위 및 기록\n",
      "1. 연도 구단순위는 KBO 한국시리즈 우승구단이 제1위, 준우승\n",
      "구단이 제2위, 그 이하는 KBO 정규시즌 승률순으로 한다.\n",
      "2. KBO 한국시리즈, KBO 플레이오프, KBO 준플레이오프, KBO\n",
      "와일드카드 결정전, 정규시즌 1위 결정전의 기록은 KBO 정규\n",
      "시즌의 기록에 가산하지 않고 별도 취급한다.\n",
      "3. KBO 정규시즌 제2, 3, 4위가 2개 구단 또는 3개 구단 이상일\n",
      "경우에는 해당 구단간 경기에서 전체 전적 다승, 해당 구단간\n",
      "경기에서 전체 다득점, 전년도 성적순으로 순위를 결정한다.\n",
      "정규시즌 제1, 5위가 2개 구단일 경우에는 와일드카드 결정전\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for doc in filtered_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dce7a1",
   "metadata": {},
   "source": [
    "### 답변 생성을 위한 RAG 체인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "992ef15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain Hub에서 프롬프트 가져오기(RAG 프롬프트는 자유롭게 수정 가능)\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc96e3",
   "metadata": {},
   "source": [
    "이제 생성한 `rag_chain` 에 질문을 전달하여 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d16e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 구단은 144경기씩 해, 총 720경기를 거행한다.\n",
      "\n",
      "**Source**\n",
      "- data/2024_프로야구_리그규정_요약.pdf (page 3)\n"
     ]
    }
   ],
   "source": [
    "# RAG 체인에 질문을 전달하여 답변 생성\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9f601",
   "metadata": {},
   "source": [
    "### 답변의 Hallucination 체커 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40ec0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할루시네이션 체크를 위한 데이터 모델 정의\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 환각 평가기 생성\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550b7cf",
   "metadata": {},
   "source": [
    "생성한 `hallucination_grader` 를 사용하여 생성된 답변의 환각 여부를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb593684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가기를 사용하여 생성된 답변의 환각 여부 평가\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110eb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 평가기를 결합하여 답변 평가기 생성\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a26ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가기를 사용하여 생성된 답변이 질문을 해결하는지 여부 평가\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc11dd",
   "metadata": {},
   "source": [
    "### 쿼리 재작성(Query Rewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9df325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# Query Rewriter 프롬프트 정의(자유롭게 수정이 가능합니다)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter 프롬프트 템플릿 생성\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter 생성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd3e83",
   "metadata": {},
   "source": [
    "생성한 `question_rewriter` 에 질문을 전달하여 개선된 질문을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6eb92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'각 구단이 시즌 동안 치르는 경기 수는 얼마인가요?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문 재작성기에 질문을 전달하여 개선된 질문 생성\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5ee42",
   "metadata": {},
   "source": [
    "### 웹 검색 도구\n",
    "\n",
    "**웹 검색 도구**는 **Adaptive RAG**의 중요한 구성 요소로, 최신 정보를 검색하는 데 사용됩니다. 이 도구는 사용자가 최신 이벤트와 관련된 질문에 대해 신속하고 정확한 답변을 얻을 수 있도록 지원합니다.\n",
    "\n",
    "- **설정**: 웹 검색 도구를 설정하여 최신 정보를 검색할 수 있도록 준비합니다.\n",
    "- **검색 수행**: 사용자의 쿼리를 기반으로 웹에서 관련 정보를 검색합니다.\n",
    "- **결과 분석**: 검색된 결과를 분석하여 사용자의 질문에 가장 적합한 정보를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e004263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 웹 검색 도구 생성\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d60abe",
   "metadata": {},
   "source": [
    "웹 검색 도구를 실행하여 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c13be8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'linktr.ee/teddynote | Linktree', 'url': 'https://linktr.ee/teddynote', 'content': '03/04 LangGraph Hands On 튜토리얼 (2시간 분량) [FastCampus] 테디노트의 RAG 비법노트🙌. 🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥. 📘 랭체인 한국어 튜토리얼🇰🇷 ... Github. 9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf.', 'score': 0.6072213, 'raw_content': None}, {'title': ' - LangChain 한국어 튜토리얼 - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 '테디노트의 RAG 비법노트' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.5999311, 'raw_content': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n\\n<랭체인LangChain 노트> - Lang…\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\nAuthor: 테디노트\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"추천\")\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다🙏🙏\\n✅ 랭체인 한국어 튜토리얼 강의\\n패스트캠퍼스 - RAG 비법노트\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\nhttps://github.com/teddylee777/langchain-kr\\n✅ 유튜브 \"테디노트\" 🎥📚\\nhttps://www.youtube.com/c/@teddynote\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\n✅ 문의 teddylee777@gmail.com\\nLICENSE\\n인용 및 출처 표기\\n\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\n\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\nCopyright (c) 테디노트.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points 형식으로 정리\"에서 \"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docx도 설치해야 할까요?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\nloads는 뭐에요?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n\\nNext : CH01 LangChain 시작하기\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send'}, {'title': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 ...', 'url': 'https://github.com/teddylee777/langchain-kr', 'content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!! 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!! 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. langchain-ai 📖 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python', 'score': 0.3684744, 'raw_content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nteddylee777 / langchain-kr Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 407\\nStar 1.4k\\n\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nLicense\\nApache-2.0 license\\n1.4k stars 407 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 2\\nPull requests 0\\nActions\\nProjects 0\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\n\\nteddylee777/langchain-kr\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n391 Commits\\n\\n|\\n| \\n01-Basic\\n| \\n01-Basic\\n| \\n| \\n|\\n| \\n02-Prompt\\n| \\n02-Prompt\\n| \\n| \\n|\\n| \\n03-OutputParser\\n| \\n03-OutputParser\\n| \\n| \\n|\\n| \\n04-Model\\n| \\n04-Model\\n| \\n| \\n|\\n| \\n05-Memory\\n| \\n05-Memory\\n| \\n| \\n|\\n| \\n06-DocumentLoader\\n| \\n06-DocumentLoader\\n| \\n| \\n|\\n| \\n07-TextSplitter\\n| \\n07-TextSplitter\\n| \\n| \\n|\\n| \\n08-Embeddings\\n| \\n08-Embeddings\\n| \\n| \\n|\\n| \\n09-VectorStore\\n| \\n09-VectorStore\\n| \\n| \\n|\\n| \\n10-Retriever\\n| \\n10-Retriever\\n| \\n| \\n|\\n| \\n11-Reranker\\n| \\n11-Reranker\\n| \\n| \\n|\\n| \\n12-RAG\\n| \\n12-RAG\\n| \\n| \\n|\\n| \\n13-LangChain-Expression-Language\\n| \\n13-LangChain-Expression-Language\\n| \\n| \\n|\\n| \\n14-Chains\\n| \\n14-Chains\\n| \\n| \\n|\\n| \\n15-Agent\\n| \\n15-Agent\\n| \\n| \\n|\\n| \\n16-Evaluations\\n| \\n16-Evaluations\\n| \\n| \\n|\\n| \\n17-LangGraph\\n| \\n17-LangGraph\\n| \\n| \\n|\\n| \\n18-FineTuning\\n| \\n18-FineTuning\\n| \\n| \\n|\\n| \\n19-Streamlit\\n| \\n19-Streamlit\\n| \\n| \\n|\\n| \\n20-Projects/01-ParsingOutput\\n| \\n20-Projects/01-ParsingOutput\\n| \\n| \\n|\\n| \\n22-OpenAI\\n| \\n22-OpenAI\\n| \\n| \\n|\\n| \\n99-Projects\\n| \\n99-Projects\\n| \\n| \\n|\\n| \\nimages\\n| \\nimages\\n| \\n| \\n|\\n| \\n.env_sample\\n| \\n.env_sample\\n| \\n| \\n|\\n| \\n.gitignore\\n| \\n.gitignore\\n| \\n| \\n|\\n| \\nLICENSE\\n| \\nLICENSE\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\npoetry.lock\\n| \\npoetry.lock\\n| \\n| \\n|\\n| \\npyproject.toml\\n| \\npyproject.toml\\n| \\n| \\n|\\n| \\nrequirements-mini.txt\\n| \\nrequirements-mini.txt\\n| \\n| \\n|\\n| \\nrequirements-onnx.txt\\n| \\nrequirements-onnx.txt\\n| \\n| \\n|\\n| \\nrequirements.txt\\n| \\nrequirements.txt\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\nApache-2.0 license\\n\\n📘 LangChain 한국어 튜토리얼\\n\\n\\n🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다.\\n본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\n📔 위키독스 전자책(무료)\\n\\n\\n위키독스에 무료 전자책을 등록하였습니다✌️\\n위키독스 페이지에서 책 \"추천\" 버튼 한 번씩만 눌러 주시면 제작에 큰 힘이 됩니다. 미리 감사 드립니다🫶\\n틈나는대로 열심히 업데이트 하고 있습니다. 앞으로도 신규 기능이 추가 될 때마다 빠르게 x100 업데이트 예정입니다.\\n\\n랭체인LangChain 노트 by 테디노트 구경하러 가기\\n\\n🍿 유튜브\\n\\n\\n🤗 huggingface 에 공개된 오픈모델을 💻 로컬PC 에서 빠르게 실행🔥 해보고 테스트 하는 방법 + 모델 서빙🚀 + 업무자동화🤖 에 적용하는 방법까지!\\n👀 코드 기반 답변하는 💻 GitHub 소스코드 기반 Q&A 챗봇🤖 제작기\\nllama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\n무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!!\\nStreamlit 으로 ChatGPT 클론 서비스 제작하는 방법\\n대화내용을 기록하는 LLM Chain 생성 방법 + 도큐먼트 참조하는 tip!\\n(Self Learning GPT) LangSmith 피드백으로 원하는 형식의 답변을 학습하는 GPT\\n(LangServe 리뷰) 초간편 LLM 웹앱 제작 & 배포기능까지! 과연, Streamlit 대체할 수 있을까?\\nAI vs AI 의대 증원에 대한 모의 찬반토론 (AI 더빙본)\\n토론 AI 에이전트 - 의대 입학정원 증원에 대한 찬반토론을 AI 끼리 한다면?\\n긴 문서(long context) 에 대한 참신한 RAG 방법론: RAPTOR! 논문 리뷰와 코드를 준비했습니다\\nLangChain 밋업 발표 / R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n노코딩으로 쇼핑몰 리뷰 분석 (크롤링 + Q&A 챗봇)\\nChatGPT 의 GPTS 에 API 호출기능을 붙이면 어떻게 될까?\\nLangChain Agent 를 활용하여 ChatGPT를 업무자동화 에 적용하는 방법🔥🔥\\nPrivate GPT! 나만의 ChatGPT 만들기 (HuggingFace Open LLM 활용)\\nLangGraph 의 멀티 에이전트 콜라보레이션 찍먹하기\\n마법같은 문법 LangChain Expression Language(LCEL)\\n이미지를 matplotlib 파이썬 코드로, 원하는 문장을 입력하면 파이썬 코드로 변환하는 방법\\nRAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작\\nOpenAI 의 새로운 기능 Assistant API 완벽히 이해해보기\\nOpenAI 의 새로운 기능 Assistant API 3가지 도구 활용법\\n\\n✏️ 블로그 글 목록\\n\\nGeneral\\n\\n\\nOpenAI API 모델 리스트 / 요금표\\n\\nOpenAI Python API\\n\\n\\nOpenAI Python API 키 발급방법, 요금체계\\n채팅(chat) 함수 사용하기(1)\\nDALL·E를 사용하여 이미지 생성, 수정, 다양화하기(2)\\nWhisper API를 사용하여 TTS, STT 구현하기(3)\\n\\nLangChain\\n\\n\\nOpenAI GPT 모델(ChatOpenAI) 사용법\\n허깅페이스(HuggingFace) 모델 사용법\\n챗(chat) - ConversationChain, 템플릿 사용법\\n정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n웹사이트 크롤링 - 웹사이트 문서 요약\\n웹사이트 정보 추출 - 스키마 활용법\\nPDF 문서요약, Map-Reduce\\nPDF 기반 질의응답(Question-Answering)\\n문장을 파이썬 코드로, 이미지를 파이썬 코드로 변경하는 방법\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\nRAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n\\nLangGraph\\n\\n\\nMulti-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n👥 LangChain 밋업 2024 Q1 발표자료\\n\\n\\nRAG - 우리가 절대 쉽게 원하는 결과물을 얻을 수 없는 이유 - 테디노트\\n프름프트 흐름과 LLM 모델 평가 - 이재석님\\n인공지능을 통한 게임 제작 파이프라인의 변화 - 김한얼님\\nOpenAI SORA 살짝 맛보기 - 박정현님\\nSemantic Kernel로 만드는 AI Copilot - 이종인님\\nStreamlit 과 langchain으로 나만의 웹서비스 개발하기 - 최재혁님\\nLlama2-koen을 만들기까지 - 최태균님\\n올바른 한국어 언어 모델 평가를 위해: HAE-RAE Bench, KMMLU - 손규진님\\n랭체인 네이버 기사 크롤링 - 우성우님\\nGemma와 LangChain을 이용한 SQL 체인만들기 - 김태영님\\n\\n📜 라이선스\\n\\n본 프로젝트는 Apache License 2.0에 따라 라이선스가 부여됩니다.\\n🚫 라이선스 고지\\n\\n🔒 본 내용의 저작권은 2024년 테디노트에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com 으로 문의할 수 있습니다.\\n```\\nCopyright 2024 테디노트(teddylee777@gmail.com)\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n```\\n인용 및 출처 표기\\n\\n본 저작물의 내용을 블로그, 유튜브 등 온라인 매체에 인용하여 게재하는 경우, 저작권법에 따라 반드시 출처를 명시 해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다.\\n\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n📚 출처\\n\\n\\nlangchain-ai 📖\\nOpenAI API Reference 🤖\\n\\n🌐 추가 자료\\n\\n\\n유튜브 채널: LangChain 한국어 튜토리얼 🎥\\n블로그: 테디노트 📝\\nPlayground: LangChain LLM Playground 🎮\\n\\n🚀 시작하기\\n\\n본 튜토리얼을 시작하기 전에, LangChain과 관련된 기본적인 지식을 갖추는 것이 좋습니다. 위의 출처 링크를 통해 기본적인 정보를 얻을 수 있습니다.\\nStart History\\n\\n\\n💡 컨트리뷰션\\n\\n본 튜토리얼에 기여하고자 하는 분들은 언제든지 풀 리퀘스트를 보내주시거나, 이슈를 등록하여 의견을 공유해 주시기 바랍니다. 모든 기여는 본 프로젝트의 발전에 큰 도움이 됩니다. 💖\\n\\nAbout\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nTopics\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\nResources\\nReadme\\nLicense\\nApache-2.0 license\\nActivity\\nStars\\n1.4k stars\\nWatchers\\n37 watching\\nForks\\n407 forks\\nReport repository\\nReleases\\nNo releases published\\nPackages 0\\nNo packages published  \\nContributors 5\\nLanguages\\n\\nJupyter Notebook 97.8%\\nPython 2.0%\\nHTML 0.2%\\n\\nFooter\\n© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou can’t perform that action at this time.'}]\n"
     ]
    }
   ],
   "source": [
    "# 웹 검색 도구 호출\n",
    "result = web_search_tool.search(\"테디노트 위키독스 랭체인 튜토리얼 URL 을 알려주세요\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1904c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'linktr.ee/teddynote | Linktree',\n",
       " 'url': 'https://linktr.ee/teddynote',\n",
       " 'content': '03/04 LangGraph Hands On 튜토리얼 (2시간 분량) [FastCampus] 테디노트의 RAG 비법노트🙌. 🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥. 📘 랭체인 한국어 튜토리얼🇰🇷 ... Github. 9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf.',\n",
       " 'score': 0.6072213,\n",
       " 'raw_content': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 웹 검색 결과의 첫 번째 결과 확인\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac37855",
   "metadata": {},
   "source": [
    "## 그래프 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab91c2",
   "metadata": {},
   "source": [
    "### 그래프 상태 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d23ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "# 그래프의 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    그래프의 상태를 나타내는 데이터 모델\n",
    "\n",
    "    Attributes:\n",
    "        question: 질문\n",
    "        generation: LLM 생성된 답변\n",
    "        documents: 도큐먼트 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266cc42",
   "metadata": {},
   "source": [
    "## 그래프 흐름 정의\n",
    "\n",
    "**그래프 흐름**을 정의하여 **Adaptive RAG**의 작동 방식을 명확히 합니다. 이 단계에서는 그래프의 상태와 전환을 설정하여 쿼리 처리의 효율성을 높입니다.\n",
    "\n",
    "- **상태 정의**: 그래프의 각 상태를 명확히 정의하여 쿼리의 진행 상황을 추적합니다.\n",
    "- **전환 설정**: 상태 간의 전환을 설정하여 쿼리가 적절한 경로를 따라 진행되도록 합니다.\n",
    "- **흐름 최적화**: 그래프의 흐름을 최적화하여 정보 검색과 생성의 정확성을 향상시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bf00c",
   "metadata": {},
   "source": [
    "### 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee6f34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 문서 검색 수행\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 답변 생성\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 각 문서에 대한 관련성 점수 계산\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # 관련성이 있는 문서 추가\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # 관련성이 없는 문서는 건너뛰기\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs}\n",
    "\n",
    "\n",
    "# 질문 재작성 노드\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 질문 재작성\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "# 웹 검색 노드\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec62cc",
   "metadata": {},
   "source": [
    "## 추가 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d33976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 라우팅 노드\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # 질문 가져오기\n",
    "    question = state[\"question\"]\n",
    "    # 질문 라우팅\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # 질문 라우팅 결과에 따른 노드 라우팅\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # 문서 검색 결과 가져오기\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 모든 문서가 관련성 없는 경우 질문 재작성\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # 관련성 있는 문서가 있는 경우 답변 생성\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # 환각 평가\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination 여부 확인\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # 답변의 관련성(Relevance) 평가\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # 관련성 평가 결과에 따른 처리\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412119d",
   "metadata": {},
   "source": [
    "### 그래프 컴파일\n",
    "\n",
    "**그래프 컴파일** 단계에서는 **Adaptive RAG**의 워크플로우를 구축하고 실행 가능한 상태로 만듭니다. 이 과정은 그래프의 각 노드와 엣지를 연결하여 쿼리 처리의 전체 흐름을 정의합니다.\n",
    "\n",
    "- **노드 정의**: 각 노드를 정의하여 그래프의 상태와 전환을 명확히 합니다.\n",
    "- **엣지 설정**: 노드 간의 엣지를 설정하여 쿼리가 적절한 경로를 따라 진행되도록 합니다.\n",
    "- **워크플로우 구축**: 그래프의 전체 흐름을 구축하여 정보 검색과 생성의 효율성을 극대화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c106a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 상태 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"web_search\", web_search)  # 웹 검색\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 문서 검색\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # 문서 평가\n",
    "workflow.add_node(\"generate\", generate)  # 답변 생성\n",
    "workflow.add_node(\"transform_query\", transform_query)  # 쿼리 변환\n",
    "\n",
    "# 그래프 빌드\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",  # 웹 검색으로 라우팅\n",
    "        \"vectorstore\": \"retrieve\",  # 벡터스토어로 라우팅\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")  # 웹 검색 후 답변 생성\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")  # 문서 검색 후 평가\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # 쿼리 변환 필요\n",
    "        \"generate\": \"generate\",  # 답변 생성 가능\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")  # 쿼리 변환 후 문서 검색\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    hallucination_check,\n",
    "    {\n",
    "        \"hallucination\": \"generate\",  # Hallucination 발생 시 재생성\n",
    "        \"relevant\": END,  # 답변의 관련성 여부 통과\n",
    "        \"not relevant\": \"transform_query\",  # 답변의 관련성 여부 통과 실패 시 쿼리 변환\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f4505",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2739b",
   "metadata": {},
   "source": [
    "## 그래프 사용\n",
    "\n",
    "**그래프 사용** 단계에서는 **Adaptive RAG**의 실행을 통해 쿼리 처리 결과를 확인합니다. 이 과정은 그래프의 각 노드와 엣지를 따라 쿼리를 처리하여 최종 결과를 생성합니다.\n",
    "\n",
    "- **그래프 실행**: 정의된 그래프를 실행하여 쿼리의 흐름을 따라갑니다.\n",
    "- **결과 확인**: 그래프 실행 후 생성된 결과를 검토하여 쿼리가 적절히 처리되었는지 확인합니다.\n",
    "- **결과 분석**: 생성된 결과를 분석하여 쿼리의 목적에 부합하는지 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"현역선수등록은 몇명이야?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"2024년 노벨 문학상 수상자는 누구인가요?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
