{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# Adaptive RAG\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì€ Adaptive RAG(Adaptive Retrieval-Augmented Generation)ì˜ êµ¬í˜„ì„ ë‹¤ë£¹ë‹ˆë‹¤. \n",
    "\n",
    "Adaptive RAGëŠ” ì¿¼ë¦¬ ë¶„ì„ê³¼ ëŠ¥ë™ì /ìê¸° ìˆ˜ì • RAGë¥¼ ê²°í•©í•˜ì—¬ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„±í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤. \n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ê³¼ ìê¸° ìˆ˜ì • RAG ê°„ì˜ ë¼ìš°íŒ…ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ë¡œ ë‹¤ë£¨ëŠ” ë‚´ìš©**\n",
    "\n",
    "- **Create Index**: ì¸ë±ìŠ¤ ìƒì„± ë° ë¬¸ì„œ ë¡œë“œ\n",
    "- **LLMs**: LLMì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ ë¼ìš°íŒ… ë° ë¬¸ì„œ í‰ê°€\n",
    "- **Web Search Tool**: ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì •\n",
    "- **Construct the Graph**: ê·¸ë˜í”„ ìƒíƒœ ë° íë¦„ ì •ì˜\n",
    "- **Compile Graph**: ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "- **Use Graph**: ê·¸ë˜í”„ ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸\n",
    "\n",
    "----\n",
    "\n",
    "**Adaptive RAG**ëŠ” **RAG**ì˜ ì „ëµìœ¼ë¡œ, (1) [ì¿¼ë¦¬ ë¶„ì„](https://blog.langchain.dev/query-construction/)ê³¼ (2) [Self-Reflective RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)ì„ ê²°í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "[ë…¼ë¬¸: Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) ì—ì„œëŠ” ì¿¼ë¦¬ ë¶„ì„ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ë¼ìš°íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `No Retrieval`\n",
    "- `Single-shot RAG`\n",
    "- `Iterative RAG`\n",
    "\n",
    "LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ êµ¬í˜„ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¼ìš°íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì›¹ ê²€ìƒ‰**: ìµœì‹  ì´ë²¤íŠ¸ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ì‚¬ìš©\n",
    "- **ìê¸° ìˆ˜ì • RAG**: ì¸ë±ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ì‚¬ìš©\n",
    "\n",
    "![adaptive-rag.png](./assets/langgraph-adaptive-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb73bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25ec196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T11:12:51.539233Z",
     "start_time": "2025-04-09T11:12:51.521051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ PDF ê¸°ë°˜ Retrieval Chain ìƒì„±\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ Retrieval Chain ì„ ìƒì„±í•©ë‹ˆë‹¤. ê°€ì¥ ë‹¨ìˆœí•œ êµ¬ì¡°ì˜ Retrieval Chain ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨, LangGraph ì—ì„œëŠ” Retirever ì™€ Chain ì„ ë”°ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ë˜ì•¼ ê° ë…¸ë“œë³„ë¡œ ì„¸ë¶€ ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "\n",
    "- ì´ì „ íŠœí† ë¦¬ì–¼ì—ì„œ ë‹¤ë£¬ ë‚´ìš©ì´ë¯€ë¡œ, ìì„¸í•œ ì„¤ëª…ì€ ìƒëµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cb77da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T11:13:01.089164Z",
     "start_time": "2025-04-09T11:12:54.405230Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "loader = PDFPlumberLoader(\"data/2024_í”„ë¡œì•¼êµ¬_ë¦¬ê·¸ê·œì •_ìš”ì•½.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = loader.load()\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = Chroma.from_documents(documents=split_docs, embedding=embeddings)\n",
    "\n",
    "pdf_retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fc536",
   "metadata": {},
   "source": [
    "## ì¿¼ë¦¬ ë¼ìš°íŒ…ê³¼ ë¬¸ì„œ í‰ê°€\n",
    "\n",
    "**LLMs** ë‹¨ê³„ì—ì„œëŠ” **ì¿¼ë¦¬ ë¼ìš°íŒ…**ê³¼ **ë¬¸ì„œ í‰ê°€**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ **Adaptive RAG**ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ìœ¼ë¡œ, íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì¿¼ë¦¬ ë¼ìš°íŒ…**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì •ë³´ ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¿¼ë¦¬ì˜ ëª©ì ì— ë§ëŠ” ìµœì ì˜ ê²€ìƒ‰ ê²½ë¡œë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- **ë¬¸ì„œ í‰ê°€**: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆê³¼ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ì—¬ ìµœì¢… ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ **LLMs**ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë‹¨ê³„ëŠ” **Adaptive RAG**ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì§€ì›í•˜ë©°, ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b78d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# ìµœì‹  LLM ëª¨ë¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë°ì´í„° ì†ŒìŠ¤ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ë°ì´í„° ëª¨ë¸\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒì„ ìœ„í•œ ë¦¬í„°ëŸ´ íƒ€ì… í•„ë“œ\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM ì´ˆê¸°í™” ë° í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to í”„ë¡œì•¼êµ¬ ë¦¬ê·¸ê·œì •.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "\n",
    "# Routing ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM ë¼ìš°í„°ë¥¼ ê²°í•©í•˜ì—¬ ì§ˆë¬¸ ë¼ìš°í„° ìƒì„±\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4d831",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ ì¿¼ë¦¬ ë¼ìš°íŒ… ê²°ê³¼ë¥¼ í…ŒìŠ¤íŠ¸ í•´ë³¸ ë’¤ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0874c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"ì•¼êµ¬ í˜„ì—­ì„ ìˆ˜ë“±ë¡ì€ ëª‡ëª…ì´ì•¼?\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d22b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "print(question_router.invoke({\"question\": \"íŒêµì—ì„œ ê°€ì¥ ë§›ìˆëŠ” ë”¤ì„¬ì§‘ ì°¾ì•„ì¤˜\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc43b99",
   "metadata": {},
   "source": [
    "### ê²€ìƒ‰ í‰ê°€ê¸°(Retrieval Grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1221d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM ì´ˆê¸°í™” ë° í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ í‰ê°€ê¸° ìƒì„±\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cac10",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ `retrieval_grader` ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa5e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì„¤ì •\n",
    "question = \"ê° êµ¬ë‹¨ì€ ëª‡ ê²½ê¸°ì”© í•´?\"\n",
    "\n",
    "# ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "docs = pdf_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "055e5e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============0============\n",
      "ì„œ ì „ì²´ ì „ì  ë‹¤ìŠ¹, í•´ë‹¹ êµ¬ë‹¨ê°„ ê²½ê¸°ì—ì„œ ì „ì²´ ë‹¤ë“ì , ì „ë…„ë„\n",
      "ì„±ì ìˆœìœ¼ë¡œ ìˆœìœ„ë¥¼ ê²°ì •í•œë‹¤.\n",
      "ë‹¨, KBO ì •ê·œì‹œì¦Œ ì œ6, 7, 8, 9, 10ìœ„ê°€ 2ê°œ êµ¬ë‹¨ ì´ìƒì¼ ê²½ìš°\n",
      "ì—ëŠ” ìŠ¹ë¥ ë¡œ ìˆœìœ„ë¥¼ ê²°ì •í•˜ë˜, ìŠ¹ë¥ ì´ ë™ì¼í•  ê²½ìš° ê³µë™ ìˆœìœ„\n",
      "ë¡œ í•œë‹¤. ë¬¸ì„œìƒ í‘œê¸°, ê°œë§‰ì „ í¸ì„±, KBO ì‹ ì¸ ë“œë˜í”„íŠ¸ ë“±\n",
      "ìˆœì„œë¥¼ í•„ìš”ë¡œ í•˜ëŠ” ê²½ìš°ì—ëŠ” í•´ë‹¹ êµ¬ë‹¨ê°„ ì „ì²´ ì „ì  ë‹¤ìŠ¹, í•´\n",
      "ë‹¹ êµ¬ë‹¨ê°„ ì „ì²´ ë‹¤ë“ì , ì „ë…„ë„ ì„±ì  ìˆœìœ„ë¡œ ìˆœì„œë¥¼ ì •í•œë‹¤.\n",
      "(2020.1.10 âœ 2022.3.29 ê°œì •)\n",
      "ì œ4ì¡° ê²½ê¸°ê·œì¹™\n",
      "KBOê°€ ì£¼ìµœí•˜ëŠ” ëª¨ë“  ê²½ê¸°ëŠ” ê³µì‹ì•¼êµ¬ê·œì¹™ì— ë”°ë¥¸ë‹¤.\n",
      "ì œ5ì¡° ê²½ê¸°ì¼ì • ê²°ì • ë° ë³€ê²½\n",
      "1. ìš°ì²œ ë° ê¸°íƒ€ ì‚¬ìœ ë¡œ ì˜ˆì •ëœ ê²½ê¸°ë¥¼ ê±°í–‰í•˜ì§€ ëª»í–ˆì„ ê²½ìš° ì´\n",
      "ì¬ê°€ ì¶”í›„ ê²°ì •í•˜ë©° ì—°ê¸°ëœ ê²½ê¸°ëŠ” í•„ìš”í•œ ê²½ìš° ì›”ìš”ì¼ ê²½ê¸°,\n",
      "ë”ë¸”í—¤ë”ë¥¼ ê±°í–‰í•  ìˆ˜ ìˆë‹¤.\n",
      "ë‹¨, ë”ë¸”í—¤ë” ì œ1ê²½ê¸°ëŠ” 9íšŒê¹Œì§€ë¡œ í•œë‹¤.\n",
      "2. ì§€ìƒíŒŒ ì¤‘ê³„ë¡œ ì¸í•´ ì‹œê°„ì„ ë³€ê²½í•  ê²½ìš°ì—ëŠ” í™ˆêµ¬ë‹¨ì´ ê²°ì •í•˜\n",
      "ì—¬ KBOì— í†µë³´í•œë‹¤. ì§€ìƒíŒŒ ì¤‘ê³„ë¡œ ì¸í•œ ì‹œê°„ ë³€ê²½ ìš”ì²­ì´ ìˆ\n",
      "----------------------------------------------------------------------------------------------------\n",
      "============1============\n",
      "ê²½ê¸°ì¶œì¥ì„ ê¸ˆì§€í•œë‹¤.\n",
      "ì œ16ì¡° ê²½ê¸°ì‚¬ìš©êµ¬ì™€ ê´€ë¦¬\n",
      "1. ê²½ê¸°ì‚¬ìš©êµ¬ëŠ” KBOê°€ ì„ ì •í•œ ê²½ê¸°ì‚¬ìš©êµ¬ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
      "2. KBOëŠ” ê²½ê¸°ì‚¬ìš©êµ¬ë¥¼ ì›” 1íšŒ êµ¬ì…í•˜ì—¬ ê° êµ¬ë‹¨ì— ê³µê¸‰í•œë‹¤. ê°\n",
      "êµ¬ë‹¨ ê²½ê¸°ì‚¬ìš©êµ¬ ë‹´ë‹¹ìëŠ” ê²½ê¸°ê°œì‹œ 1ì‹œê°„ ì „ì— ì‹¬íŒìœ„ì›ì—ê²Œ\n",
      "ì´ë¥¼ ì „ë‹¬í•˜ê³  ì‹¬íŒìœ„ì›ì€ ë´‰ì¸í•´ì œ ë° ê³µ ìƒíƒœë¥¼ ì ê²€í•œ ì´í›„\n",
      "ì— ê²½ê¸°ì— ì‚¬ìš©í•œë‹¤. êµ¬ë‹¨ì— ê²½ê¸°ì‚¬ìš©êµ¬ê°€ ì „ë‹¬ëœ ì´í›„ì—ëŠ” êµ¬\n",
      "ë‹¨ ë‹´ë‹¹ìê°€ ê²½ê¸°ì‚¬ìš©êµ¬ì˜ ê´€ë¦¬ ì±…ì„ì„ ë§¡ëŠ”ë‹¤.\n",
      "10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "============2============\n",
      "ì œ1ì¥ KBO ì •ê·œì‹œì¦Œ\n",
      "ì œ1ì¡° ê²½ê¸°ë°©ì‹\n",
      "1. ë‹¨ì¼ ë¦¬ê·¸ì œë¡œ ê° êµ¬ë‹¨ì€ 144ê²½ê¸°(êµ¬ë‹¨ê°„ 16ì°¨ì „)ì”©\n",
      "ì´ 720ê²½ê¸°ë¥¼ ê±°í–‰í•œë‹¤.\n",
      "2. ì—°ì¥ì „ì€ 12íšŒ(KBO í¬ìŠ¤íŠ¸ì‹œì¦Œ 15íšŒ)ê¹Œì§€ë¡œ í•˜ê³  ìŠ¹íŒ¨ë¥¼\n",
      "ê°€ë¦¬ì§€ ëª»í•  ê²½ìš°ì—ëŠ” ë¬´ìŠ¹ë¶€ë¡œ í•œë‹¤.\n",
      "ì œ2ì¡° ìŠ¹ë¥ ê³„ì‚°ë²•\n",
      "ìŠ¹ë¥ ì€ ìŠ¹ìˆ˜/(ìŠ¹ìˆ˜ï¼‹íŒ¨ìˆ˜)ë¡œ í•œë‹¤.\n",
      "ì œ3ì¡° ì—°ë„ êµ¬ë‹¨ìˆœìœ„ ë° ê¸°ë¡\n",
      "1. ì—°ë„ êµ¬ë‹¨ìˆœìœ„ëŠ” KBO í•œêµ­ì‹œë¦¬ì¦ˆ ìš°ìŠ¹êµ¬ë‹¨ì´ ì œ1ìœ„, ì¤€ìš°ìŠ¹\n",
      "êµ¬ë‹¨ì´ ì œ2ìœ„, ê·¸ ì´í•˜ëŠ” KBO ì •ê·œì‹œì¦Œ ìŠ¹ë¥ ìˆœìœ¼ë¡œ í•œë‹¤.\n",
      "2. KBO í•œêµ­ì‹œë¦¬ì¦ˆ, KBO í”Œë ˆì´ì˜¤í”„, KBO ì¤€í”Œë ˆì´ì˜¤í”„, KBO\n",
      "ì™€ì¼ë“œì¹´ë“œ ê²°ì •ì „, ì •ê·œì‹œì¦Œ 1ìœ„ ê²°ì •ì „ì˜ ê¸°ë¡ì€ KBO ì •ê·œ\n",
      "ì‹œì¦Œì˜ ê¸°ë¡ì— ê°€ì‚°í•˜ì§€ ì•Šê³  ë³„ë„ ì·¨ê¸‰í•œë‹¤.\n",
      "3. KBO ì •ê·œì‹œì¦Œ ì œ2, 3, 4ìœ„ê°€ 2ê°œ êµ¬ë‹¨ ë˜ëŠ” 3ê°œ êµ¬ë‹¨ ì´ìƒì¼\n",
      "ê²½ìš°ì—ëŠ” í•´ë‹¹ êµ¬ë‹¨ê°„ ê²½ê¸°ì—ì„œ ì „ì²´ ì „ì  ë‹¤ìŠ¹, í•´ë‹¹ êµ¬ë‹¨ê°„\n",
      "ê²½ê¸°ì—ì„œ ì „ì²´ ë‹¤ë“ì , ì „ë…„ë„ ì„±ì ìˆœìœ¼ë¡œ ìˆœìœ„ë¥¼ ê²°ì •í•œë‹¤.\n",
      "ì •ê·œì‹œì¦Œ ì œ1, 5ìœ„ê°€ 2ê°œ êµ¬ë‹¨ì¼ ê²½ìš°ì—ëŠ” ì™€ì¼ë“œì¹´ë“œ ê²°ì •ì „\n",
      "----------------------------------------------------------------------------------------------------\n",
      "============3============\n",
      "3. ë´‰ì¸í•´ì œ í›„ ê²½ê¸° ì¤‘ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ê¸°ì‚¬ìš©êµ¬ëŠ” ê²½ê¸°ì¢…ë£Œ í›„\n",
      "ì‹¬íŒìœ„ì›ì´ ë³„ë„ë¡œ ë´‰ì¸í•˜ì—¬ ë‹¤ìŒ ê²½ê¸°ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.\n",
      "ì œ17ì¡° êµ¬ë‹¨ê¸° ê²Œì–‘\n",
      "í™ˆêµ¬ë‹¨ì€ ì „ êµ¬ë‹¨ê¸°ë¥¼ ìƒë¹„í•˜ì—¬ ê²½ê¸°ê°€ í–‰í•˜ì—¬ì§€ëŠ” ë‹¹ì¼ ì–‘ êµ¬ë‹¨\n",
      "ê¸°ë¥¼ ê²Œì–‘í•˜ì—¬ì•¼ í•œë‹¤.\n",
      "ì „ë…„ë„ ìš°ìŠ¹êµ¬ë‹¨ì€ êµ¬ë‹¨ê¸°ì™€ ì†Œì •ì˜ ìš°ìŠ¹ê¸°ë¥¼ í•¨ê»˜ ê²Œì–‘í•˜ì—¬ì•¼\n",
      "í•œë‹¤.\n",
      "ì œ18ì¡° ì…ì¥ìš”ê¸ˆ\n",
      "ì…ì¥ìš”ê¸ˆì€ ê° êµ¬ë‹¨ì´ ììœ¨ì ìœ¼ë¡œ ê²°ì •í•˜ì—¬ ì‹œí–‰í•œë‹¤.\n",
      "ì œ19ì¡° ì‘ì›ì‹œ ê¸ˆì§€ì‚¬í•­\n",
      "êµ¬ì¥ ë‚´ì˜ ê´€ê°ì„ì—ì„œ ì•°í”„(AMP)ë¥¼ ì‚¬ìš©í•˜ëŠ” ë“± ê³¼ë„í•œ ì‘ì› í–‰\n",
      "ìœ„ë¡œ ê´€ê°ì—ê²Œ ë¶ˆì¾Œê°ì„ ì£¼ê±°ë‚˜ ê²½ê¸°ì— ì§€ì¥ì„ ì¤„ ê²½ìš° ì£¼ì‹¬ì€ ê²½\n",
      "ê¸°ê´€ë¦¬ì¸ì—ê²Œ ì‘ì› í–‰ìœ„ì˜ ì¤‘ì§€ë¥¼ ìš”ì²­í•  ìˆ˜ ìˆë‹¤.\n",
      "ì œ20ì¡° ê²½ê¸°ì¤‘ì§€ì— ë”°ë¥¸ ì…ì¥ìš”ê¸ˆ ì²˜ë¦¬\n",
      "1. ë…¸ê²Œì„ì´ ì„ ê³ ë˜ì—ˆì„ ë•Œ ë™ì¼êµ¬ì¥ì˜ ë‹¤ìŒ ê²½ê¸°ì— ì…ì¥í•  ìˆ˜ ìˆ\n",
      "ë„ë¡ í•œë‹¤.\n",
      "2. ì •ì‹ê²½ê¸°(ì„œìŠ¤íœë””ë“œ ê²½ê¸° í¬í•¨) ë˜ëŠ” ì •ì‹ ë¬´ìŠ¹ë¶€ ê²½ê¸°ê°€ ë˜\n",
      "ì—ˆì„ ë•Œ ì „ì•¡ ì§•ìˆ˜í•œë‹¤.\n",
      "11\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"============{i}============\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef397b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce41bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„í„°ë§ í•˜ëŠ” ì½”ë“œ ì˜ˆì‹œ\n",
    "filtered_docs = []\n",
    "for doc in docs:\n",
    "    result = retrieval_grader.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content,\n",
    "        }\n",
    "    )\n",
    "    if result.binary_score == \"yes\":\n",
    "        filtered_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20f9275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œ1ì¥ KBO ì •ê·œì‹œì¦Œ\n",
      "ì œ1ì¡° ê²½ê¸°ë°©ì‹\n",
      "1. ë‹¨ì¼ ë¦¬ê·¸ì œë¡œ ê° êµ¬ë‹¨ì€ 144ê²½ê¸°(êµ¬ë‹¨ê°„ 16ì°¨ì „)ì”©\n",
      "ì´ 720ê²½ê¸°ë¥¼ ê±°í–‰í•œë‹¤.\n",
      "2. ì—°ì¥ì „ì€ 12íšŒ(KBO í¬ìŠ¤íŠ¸ì‹œì¦Œ 15íšŒ)ê¹Œì§€ë¡œ í•˜ê³  ìŠ¹íŒ¨ë¥¼\n",
      "ê°€ë¦¬ì§€ ëª»í•  ê²½ìš°ì—ëŠ” ë¬´ìŠ¹ë¶€ë¡œ í•œë‹¤.\n",
      "ì œ2ì¡° ìŠ¹ë¥ ê³„ì‚°ë²•\n",
      "ìŠ¹ë¥ ì€ ìŠ¹ìˆ˜/(ìŠ¹ìˆ˜ï¼‹íŒ¨ìˆ˜)ë¡œ í•œë‹¤.\n",
      "ì œ3ì¡° ì—°ë„ êµ¬ë‹¨ìˆœìœ„ ë° ê¸°ë¡\n",
      "1. ì—°ë„ êµ¬ë‹¨ìˆœìœ„ëŠ” KBO í•œêµ­ì‹œë¦¬ì¦ˆ ìš°ìŠ¹êµ¬ë‹¨ì´ ì œ1ìœ„, ì¤€ìš°ìŠ¹\n",
      "êµ¬ë‹¨ì´ ì œ2ìœ„, ê·¸ ì´í•˜ëŠ” KBO ì •ê·œì‹œì¦Œ ìŠ¹ë¥ ìˆœìœ¼ë¡œ í•œë‹¤.\n",
      "2. KBO í•œêµ­ì‹œë¦¬ì¦ˆ, KBO í”Œë ˆì´ì˜¤í”„, KBO ì¤€í”Œë ˆì´ì˜¤í”„, KBO\n",
      "ì™€ì¼ë“œì¹´ë“œ ê²°ì •ì „, ì •ê·œì‹œì¦Œ 1ìœ„ ê²°ì •ì „ì˜ ê¸°ë¡ì€ KBO ì •ê·œ\n",
      "ì‹œì¦Œì˜ ê¸°ë¡ì— ê°€ì‚°í•˜ì§€ ì•Šê³  ë³„ë„ ì·¨ê¸‰í•œë‹¤.\n",
      "3. KBO ì •ê·œì‹œì¦Œ ì œ2, 3, 4ìœ„ê°€ 2ê°œ êµ¬ë‹¨ ë˜ëŠ” 3ê°œ êµ¬ë‹¨ ì´ìƒì¼\n",
      "ê²½ìš°ì—ëŠ” í•´ë‹¹ êµ¬ë‹¨ê°„ ê²½ê¸°ì—ì„œ ì „ì²´ ì „ì  ë‹¤ìŠ¹, í•´ë‹¹ êµ¬ë‹¨ê°„\n",
      "ê²½ê¸°ì—ì„œ ì „ì²´ ë‹¤ë“ì , ì „ë…„ë„ ì„±ì ìˆœìœ¼ë¡œ ìˆœìœ„ë¥¼ ê²°ì •í•œë‹¤.\n",
      "ì •ê·œì‹œì¦Œ ì œ1, 5ìœ„ê°€ 2ê°œ êµ¬ë‹¨ì¼ ê²½ìš°ì—ëŠ” ì™€ì¼ë“œì¹´ë“œ ê²°ì •ì „\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for doc in filtered_docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dce7a1",
   "metadata": {},
   "source": [
    "### ë‹µë³€ ìƒì„±ì„ ìœ„í•œ RAG ì²´ì¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "992ef15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain Hubì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°(RAG í”„ë¡¬í”„íŠ¸ëŠ” ììœ ë¡­ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# RAG ì²´ì¸ ìƒì„±\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc96e3",
   "metadata": {},
   "source": [
    "ì´ì œ ìƒì„±í•œ `rag_chain` ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d16e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê° êµ¬ë‹¨ì€ 144ê²½ê¸°ì”© í•´, ì´ 720ê²½ê¸°ë¥¼ ê±°í–‰í•œë‹¤.\n",
      "\n",
      "**Source**\n",
      "- data/2024_í”„ë¡œì•¼êµ¬_ë¦¬ê·¸ê·œì •_ìš”ì•½.pdf (page 3)\n"
     ]
    }
   ],
   "source": [
    "# RAG ì²´ì¸ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9f601",
   "metadata": {},
   "source": [
    "### ë‹µë³€ì˜ Hallucination ì²´ì»¤ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40ec0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬ë¥¼ ìœ„í•œ ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í™˜ê° í‰ê°€ê¸° ìƒì„±\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550b7cf",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ `hallucination_grader` ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì˜ í™˜ê° ì—¬ë¶€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb593684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í‰ê°€ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì˜ í™˜ê° ì—¬ë¶€ í‰ê°€\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110eb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•œ LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM í‰ê°€ê¸°ë¥¼ ê²°í•©í•˜ì—¬ ë‹µë³€ í‰ê°€ê¸° ìƒì„±\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a26ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í‰ê°€ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ”ì§€ ì—¬ë¶€ í‰ê°€\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc11dd",
   "metadata": {},
   "source": [
    "### ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9df325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# Query Rewriter í”„ë¡¬í”„íŠ¸ ì •ì˜(ììœ ë¡­ê²Œ ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter ìƒì„±\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd3e83",
   "metadata": {},
   "source": [
    "ìƒì„±í•œ `question_rewriter` ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ê°œì„ ëœ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6eb92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ê° êµ¬ë‹¨ì´ ì‹œì¦Œ ë™ì•ˆ ì¹˜ë¥´ëŠ” ê²½ê¸° ìˆ˜ëŠ” ì–¼ë§ˆì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì¬ì‘ì„±ê¸°ì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ê°œì„ ëœ ì§ˆë¬¸ ìƒì„±\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5ee42",
   "metadata": {},
   "source": [
    "### ì›¹ ê²€ìƒ‰ ë„êµ¬\n",
    "\n",
    "**ì›¹ ê²€ìƒ‰ ë„êµ¬**ëŠ” **Adaptive RAG**ì˜ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œë¡œ, ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ì‚¬ìš©ìê°€ ìµœì‹  ì´ë²¤íŠ¸ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ëŒ€í•´ ì‹ ì†í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì–»ì„ ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì„¤ì •**: ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì„¤ì •í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "- **ê²€ìƒ‰ ìˆ˜í–‰**: ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›¹ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "- **ê²°ê³¼ ë¶„ì„**: ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e004263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d60abe",
   "metadata": {},
   "source": [
    "ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c13be8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'linktr.ee/teddynote | Linktree', 'url': 'https://linktr.ee/teddynote', 'content': '03/04 LangGraph Hands On íŠœí† ë¦¬ì–¼ (2ì‹œê°„ ë¶„ëŸ‰) [FastCampus] í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸ğŸ™Œ. ğŸ”¥[100% ë¬´ë£Œ] í…Œë””ë…¸íŠ¸ YouTube ì½˜í…ì¸  í•™ìŠµ ìˆœì„œğŸ”¥. ğŸ“˜ ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· ... Github. 9/21 í…Œë””ë…¸íŠ¸-Gencon2024-ModularRAG-20240921.pdf.', 'score': 0.6072213, 'raw_content': None}, {'title': ' - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. ì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”? CH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m. ì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— 'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.5999311, 'raw_content': '<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· - WikiDocs\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· CH01 LangChain ì‹œì‘í•˜ê¸° 01. ì„¤ì¹˜ ì˜ìƒë³´ê³  ë”°ë¼í•˜ê¸° 02. OpenAI API í‚¤ ë°œê¸‰ ë° í…ŒìŠ¤íŠ¸ 03. LangSmith ì¶”ì  ì„¤ì • 04. OpenAI API ì‚¬ìš©(GPT-4o ë©€í‹°ëª¨ë‹¬) 05. LangChain Expression Language(LCEL) 06. LCEL ì¸í„°í˜ì´ìŠ¤ 07. Runnable CH02 í”„ë¡¬í”„íŠ¸(Prompt) 01. í”„ë¡¬í”„íŠ¸(Prompt) 02. í“¨ìƒ· í”„ë¡¬í”„íŠ¸(FewShotPromptTemplate) 03. LangChain Hub 04. ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸(Hubì— ì—…ë¡œë“œ) CH03 ì¶œë ¥ íŒŒì„œ(Output Parsers) 01. Pydantic ì¶œë ¥ íŒŒì„œ(PydanticOutputParser) 02. ì½¤ë§ˆ êµ¬ë¶„ì ì¶œë ¥ íŒŒì„œ(CommaSeparatedListOutputParser) 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ(StructuredOuputParser) 04. JSON ì¶œë ¥ íŒŒì„œ(JsonOutputParser) 05. ë°ì´í„°í”„ë ˆì„ ì¶œë ¥ íŒŒì„œ(PandasDataFrameOutputParser) 06. ë‚ ì§œ í˜•ì‹ ì¶œë ¥ íŒŒì„œ(DatetimeOutputParser) 07. ì—´ê±°í˜• ì¶œë ¥ íŒŒì„œ(EnumOutputParser) 08. ì¶œë ¥ ìˆ˜ì • íŒŒì„œ(OutputFixingParser) CH04 ëª¨ë¸(Model) 01. ë‹¤ì–‘í•œ LLM ëª¨ë¸ í™œìš© 02. ìºì‹±(Cache) 03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° 04. í† í° ì‚¬ìš©ëŸ‰ í™•ì¸ 05. êµ¬ê¸€ ìƒì„± AI(Google Generative AI) 06. í—ˆê¹…í˜ì´ìŠ¤ ì—”ë“œí¬ì¸íŠ¸(HuggingFace Endpoints) 07. í—ˆê¹…í˜ì´ìŠ¤ ë¡œì»¬(HuggingFace Local) 08. í—ˆê¹…í˜ì´ìŠ¤ íŒŒì´í”„ë¼ì¸(HuggingFace Pipeline) 09. ì˜¬ë¼ë§ˆ(Ollama) 10. GPT4ALL 11. ë¹„ë””ì˜¤(Video) ì§ˆì˜ ì‘ë‹µ LLM (Gemini) CH05 ë©”ëª¨ë¦¬(Memory) 01. ëŒ€í™” ë²„í¼ ë©”ëª¨ë¦¬(ConversationBufferMemory) 02. ëŒ€í™” ë²„í¼ ìœˆë„ìš° ë©”ëª¨ë¦¬(ConversationBufferWindowMemory) 03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) 04. ëŒ€í™” ì—”í‹°í‹° ë©”ëª¨ë¦¬(ConversationEntityMemory) 05. ëŒ€í™” ì§€ì‹ê·¸ë˜í”„ ë©”ëª¨ë¦¬(ConversationKGMemory) 06. ëŒ€í™” ìš”ì•½ ë©”ëª¨ë¦¬(ConversationSummaryMemory) 07. ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ ë©”ëª¨ë¦¬(VectorStoreRetrieverMemory) 08. LCEL Chain ì— ë©”ëª¨ë¦¬ ì¶”ê°€ 09. SQLite ì— ëŒ€í™”ë‚´ìš© ì €ì¥ 10. RunnableWithMessageHistoryì— ChatMessageHistoryì¶”ê°€ CH06 ë¬¸ì„œ ë¡œë”(Document Loader) 01. ë„íë¨¼íŠ¸(Document) ì˜ êµ¬ì¡° 02. PDF 03. í•œê¸€(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. ì›¹ ë¬¸ì„œ(WebBaseLoader) 09. í…ìŠ¤íŠ¸(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 í…ìŠ¤íŠ¸ ë¶„í• (Text Splitter) 01. ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (CharacterTextSplitter) 02. ì¬ê·€ì  ë¬¸ì í…ìŠ¤íŠ¸ ë¶„í• (RecursiveCharacterTextSplitter) 03. í† í° í…ìŠ¤íŠ¸ ë¶„í• (TokenTextSplitter) 04. ì‹œë©˜í‹± ì²­ì»¤(SemanticChunker) 05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) 06. ë§ˆí¬ë‹¤ìš´ í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (MarkdownHeaderTextSplitter) 07. HTML í—¤ë” í…ìŠ¤íŠ¸ ë¶„í• (HTMLHeaderTextSplitter) 08. ì¬ê·€ì  JSON ë¶„í• (RecursiveJsonSplitter) CH08 ì„ë² ë”©(Embedding) 01. OpenAIEmbeddings 02. ìºì‹œ ì„ë² ë”©(CacheBackedEmbeddings) 03. í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”©(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL ì„ë² ë”© 07. Llama CPP ì„ë² ë”© CH09 ë²¡í„°ì €ì¥ì†Œ(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 ê²€ìƒ‰ê¸°(Retriever) 01. ë²¡í„°ìŠ¤í† ì–´ ê¸°ë°˜ ê²€ìƒ‰ê¸°(VectorStore-backed Retriever) 02. ë¬¸ë§¥ ì••ì¶• ê²€ìƒ‰ê¸°(ContextualCompressionRetriever) 03. ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) 04. ê¸´ ë¬¸ë§¥ ì¬ì •ë ¬(LongContextReorder) 05. ìƒìœ„ ë¬¸ì„œ ê²€ìƒ‰ê¸°(ParentDocumentRetriever) 06. ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(MultiQueryRetriever) 07. ë‹¤ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(MultiVectorRetriever) 08. ì…€í”„ ì¿¼ë¦¬ ê²€ìƒ‰ê¸°(SelfQueryRetriever) 09. ì‹œê°„ ê°€ì¤‘ ë²¡í„°ì €ì¥ì†Œ ê²€ìƒ‰ê¸°(TimeWeightedVectorStoreRetriever) 10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° 11. Convex Combination(CC) ì ìš©ëœ ì•™ìƒë¸” ê²€ìƒ‰ê¸°(EnsembleRetriever) CH11 ë¦¬ë­ì»¤(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF ë¬¸ì„œ ê¸°ë°˜ QA(Question-Answer) 02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) 03. RAG ì˜ ê¸°ëŠ¥ë³„ ë‹¤ì–‘í•œ ëª¨ë“ˆ í™œìš©ê¸° 04. RAPTOR: ê¸´ ë¬¸ë§¥ ìš”ì•½(Long Context Summary) 05. ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ëŠ” RAG ì²´ì¸ CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í†  03. RunnableLambda 04. LLM ì²´ì¸ ë¼ìš°íŒ…(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. ë™ì  ì†ì„± ì§€ì •(configurable_fields, configurable_alternatives) 07. @chain ë°ì½”ë ˆì´í„°ë¡œ Runnable êµ¬ì„± 08. RunnableWithMessageHistory 09. ì‚¬ìš©ì ì •ì˜ ì œë„¤ë ˆì´í„°(generator) 10. Runtime Arguments ë°”ì¸ë”© 11. í´ë°±(fallback) ëª¨ë¸ ì§€ì • CH14 ì²´ì¸(Chains) 01. ë¬¸ì„œ ìš”ì•½ 02. SQL 03. êµ¬ì¡°í™”ëœ ì¶œë ¥ ì²´ì¸(with_structered_output) CH15 í‰ê°€(Evaluations) 01. í•©ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±(RAGAS) 02. RAGAS ë¥¼ í™œìš©í•œ í‰ê°€ 03. ìƒì„±í•œ í‰ê°€ìš© ë°ì´í„°ì…‹ ì—…ë¡œë“œ(HuggingFace Dataset) 04. LangSmith ë°ì´í„°ì…‹ ìƒì„± 05. LLM-as-Judge 06. ì„ë² ë”© ê¸°ë°˜ í‰ê°€(embedding_distance) 07. ì‚¬ìš©ì ì •ì˜(Custom) LLM í‰ê°€ 08. Rouge, BLEU, METEOR, SemScore ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± í‰ê°€ 09. ì‹¤í—˜(Experiment) í‰ê°€ ë¹„êµ 10. ìš”ì•½(Summary) ë°©ì‹ì˜ í‰ê°€ 11. Groundedness(í• ë£¨ì‹œë„¤ì´ì…˜) í‰ê°€ 12. ì‹¤í—˜ ë¹„êµ(Pairwise Evaluation) 13. ë°˜ë³µ í‰ê°€ 14. ì˜¨ë¼ì¸ í‰ê°€ë¥¼ í™œìš©í•œ í‰ê°€ ìë™í™” CH16 ì—ì´ì „íŠ¸(Agent) 01. ë„êµ¬(Tools) 02. ë„êµ¬ ë°”ì¸ë”©(Binding Tools) 03. ì—ì´ì „íŠ¸(Agent) 04. Claude, Gemini, Ollama, Together.ai ë¥¼ í™œìš©í•œ Agent 05. Iteration ê¸°ëŠ¥ê³¼ ì‚¬ëŒ ê°œì…(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel ë°ì´í„° ë¶„ì„ Agent 08. Toolkits í™œìš© Agent 09. RAG + Image Generator Agent(ë³´ê³ ì„œ ì‘ì„±) 10. ë„êµ¬ë¥¼ í™œìš©í•œ í† ë¡  ì—ì´ì „íŠ¸(Two Agent Debates with Tools) CH17 LangGraph 01. í•µì‹¬ ê¸°ëŠ¥ 01. LangGraph ì— ìì£¼ ë“±ì¥í•˜ëŠ” Python ë¬¸ë²•ì´í•´ 02. LangGraphë¥¼ í™œìš©í•œ ì±—ë´‡ êµ¬ì¶• 03. LangGraphë¥¼ í™œìš©í•œ Agent êµ¬ì¶• 04. Agent ì— ë©”ëª¨ë¦¬(memory) ì¶”ê°€ 05. ë…¸ë“œì˜ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ 06. Human-in-the-loop(ì‚¬ëŒì˜ ê°œì…) 07. ì¤‘ê°„ë‹¨ê³„ ê°œì… ë˜ëŒë¦¼ì„ í†µí•œ ìƒíƒœ ìˆ˜ì •ê³¼ Replay 08. ì‚¬ëŒ(Human)ì—ê²Œ ë¬¼ì–´ë³´ëŠ” ë…¸ë“œ ì¶”ê°€ 09. ë©”ì‹œì§€ ì‚­ì œ(RemoveMessage) 10. ToolNode ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ë²• 11. ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¶„ê¸° ìƒì„± ë°©ë²• 12. ëŒ€í™” ê¸°ë¡ ìš”ì•½ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²• 13. ì„œë¸Œê·¸ë˜í”„ ì¶”ê°€ ë° ì‚¬ìš© ë°©ë²• 14. ì„œë¸Œê·¸ë˜í”„ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ë³€í™˜í•˜ëŠ” ë°©ë²• 15. LangGraph ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì˜ ëª¨ë“  ê²ƒ 02. êµ¬ì¡° ì„¤ê³„ 01. ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± 02. Naive RAG 03. ê´€ë ¨ì„± ì²´ì»¤(Relevance Checker) ëª¨ë“ˆ ì¶”ê°€ 04. ì›¹ ê²€ìƒ‰ ëª¨ë“ˆ ì¶”ê°€ 05. ì¿¼ë¦¬ ì¬ì‘ì„± ëª¨ë“ˆ ì¶”ê°€ 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. ì—ì´ì „íŠ¸ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ (ê³ ê° ì‘ëŒ€ ì‹œë‚˜ë¦¬ì˜¤) 02. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ë©”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì—ì´ì „íŠ¸ 03. CRAG(Corrective RAG) 04. Self-RAG 05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) 06. ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ë„¤íŠ¸ì›Œí¬(Multi-Agent Collaboration Network) 07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) 08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) 09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ 10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ CH18 ê¸°íƒ€ ì •ë³´ 01. StreamEvent íƒ€ì…ë³„ ì •ë¦¬\\nPublished with WikiDocs\\n\\n\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - Langâ€¦\\n\\n\\në„ì„œ ì¦ì • ì´ë²¤íŠ¸ !!\\n\\nWikiDocs\\n\\n<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·\\n\\nAuthor: í…Œë””ë…¸íŠ¸\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"ì¶”ì²œ\")\\nì¶”ì²œì€ ê³µìœ í•  ìˆ˜ ìˆëŠ” ë¬´ë£Œ ì „ìì±…ì„ ì§‘í•„í•˜ëŠ”ë° ì •ë§ í° í˜ì´ ë©ë‹ˆë‹¤. \"ì¶”ì²œ\" í•œ ë²ˆì”©ë§Œ ë¶€íƒ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ğŸ™ğŸ™\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ê°•ì˜\\níŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ - RAG ë¹„ë²•ë…¸íŠ¸\\nâœ… ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ì½”ë“œì €ì¥ì†Œ(GitHub) ğŸ“˜ğŸ–¥ï¸\\nhttps://github.com/teddylee777/langchain-kr\\nâœ… ìœ íŠœë¸Œ \"í…Œë””ë…¸íŠ¸\" ğŸ¥ğŸ“š\\nhttps://www.youtube.com/c/@teddynote\\nâœ… ë°ì´í„° ë¶„ì„ ë¸”ë¡œê·¸ https://teddylee777.github.io\\nâœ… ë¬¸ì˜ teddylee777@gmail.com\\nLICENSE\\nì¸ìš© ë° ì¶œì²˜ í‘œê¸°\\n\\në³¸ ì €ì‘ë¬¼ì„ ë¸”ë¡œê·¸, ìœ íŠœë¸Œ ë“± ì˜¨ë¼ì¸ ë§¤ì²´ì— ì¸ìš©í•˜ì—¬ ê²Œì¬í•  ê²½ìš°, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n\\nìƒì—…ì  ì‚¬ìš©ì— ëŒ€í•œ ì‚¬ì „ í˜‘ì˜\\n\\në³¸ ì €ì‘ë¬¼(Wikidocs ë° ê´€ë ¨ ì‹¤ìŠµ ì½”ë“œ í¬í•¨)ì„ ê°•ì˜, ê°•ì—° ë“± ìƒì—…ì  ëª©ì ìœ¼ë¡œ í™œìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš°, ì €ì‘ê¶Œìì™€ì˜ ì‚¬ì „ ì„œë©´ í˜‘ì˜ê°€ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬ë©ë‹ˆë‹¤. í•´ë‹¹ í˜‘ì˜ëŠ” teddylee777@gmail.comìœ¼ë¡œ ë¬¸ì˜í•˜ì—¬ ì§„í–‰í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në³¸ ì €ì‘ë¬¼ì€ 2024ë…„ í…Œë””ë…¸íŠ¸ì— ì˜í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. \\nëª¨ë“  ê¶Œë¦¬ëŠ” ì €ì‘ê¶Œìì—ê²Œ ìˆìœ¼ë©°, ë³¸ ì €ì‘ë¬¼ì€ Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë°°í¬ë©ë‹ˆë‹¤.\\në³¸ ì €ì‘ë¬¼ì˜ ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬ë¥¼ ê¸ˆì§€í•˜ë©°, ì „ì²´ í˜¹ì€ ì¼ë¶€ë¥¼ ì¸ìš©í•  ê²½ìš° ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\në³¸ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nCopyright (c) í…Œë””ë…¸íŠ¸.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ QA(Question-Answer) - ê¹€ë¯¼ê²¸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points í˜•ì‹ìœ¼ë¡œ ì •ë¦¬\"ì—ì„œ \"ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\" ë¼ê³  ë‚˜ì˜¤ëŠ”ë° ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? kmk582@naver.com\\n10. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°(Kiwi, Kkma, Okt) + BM25 ê²€ìƒ‰ê¸° - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\nì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ, kiwi tokenizerì„ ì‚¬ìš©í•œ ê²°ê³¼ì™€ kkma, okt ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ê°€ í° ì°¨ì´ê°€ ì—†ë‹¤ê³  ë´ë„ ë˜ëŠ” ê±´ê°€ìš”?\\nCH01 LangChain ì‹œì‘í•˜ê¸° - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\nì¢‹ì€ ìë£Œë¥¼ ë¬´ë£Œë¡œ ê³µìœ í•´ ì£¼ì…”ì„œ, ê°ì‚¬í•œ ë§ˆìŒì— \\'í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸\\' ê°•ì˜ ë“±ë¡í–ˆìŠµë‹ˆë‹¤ ! ë¬¼ë¡  ì œ í˜„ì—…ì— í•„ìš”í•œ ê¸°ìˆ ì´ë¼ì„œ, ê°•ì˜ ë˜í•œ ê¸°ìœ ë§ˆìŒì— ì‹ ì²­í–ˆêµ¬ìš” ~ ì •ì£¼í–‰ í•´ì„œ, ì°½ê³µì„ ë‚ ì•„ê°€ ë³´ê² ìŠµë‹ˆë‹¤ ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docxë„ ì„¤ì¹˜í•´ì•¼ í• ê¹Œìš”?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq ë¶€ë¶„ì´ ë“¤ì–´ê°€ì•¼ í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border ì´ ë¶€ë¶„ì´ ì¶œë ¥ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ ì½”ë“œì¸ ê²ƒì²˜ëŸ¼ í‘œì‹œë˜ì–´ ìˆë„¤ìš”~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\nê°ì‚¬íˆ ì˜ ì°¸ê³ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì£¼ ì‚¬ì†Œí•œ ì˜¤ê¸°ì´ì§€ë§Œ... 11ë²ˆ Arxiv ë‹¤ìŒì— 12ë²ˆì´ ì™€ì•¼ í•  í…ë°, ì›ë˜ ë„£ìœ¼ì‹œë ¤ë˜ ë‹¤ë¥¸ ëª©ì°¨ê°€ ë¹ ì§„ ê²ƒì¸ì§€ ë°”ë¡œ 13ë²ˆì´ ë‚˜ì™”ë„¤ìš”^^\\n03. ëª¨ë¸ ì§ë ¬í™”(Serialization) - ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° - ë™êµ¬, Sept. 20, 2024, 12:58 p.m.\\nloadsëŠ” ë­ì—ìš”?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n03. ëŒ€í™” í† í° ë²„í¼ ë©”ëª¨ë¦¬(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n05. ì½”ë“œ ë¶„í• (Python, Markdown, JAVA, C++, C#, GO, JS, Latex ë“±) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n10. STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n05. ê³„íš í›„ ì‹¤í–‰(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n07. ë©€í‹° ì—ì´ì „íŠ¸ ê°ë…ì(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n08. ê³„ì¸µì  ë©€í‹° ì—ì´ì „íŠ¸ íŒ€(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n09. SQL ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5eâ€¦\\n\\nNext : CH01 LangChain ì‹œì‘í•˜ê¸°\\n\\n\\nÃ—\\nì±…ê°ˆí”¼\\nì¶”ê°€ ë‹«ê¸°\\n\\nÃ—\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\nâ€» Feedback is delivered to the author by email.\\nClose Send'}, {'title': 'GitHub - teddylee777/langchain-kr: LangChain ê³µì‹ Document, Cookbook, ê·¸ ...', 'url': 'https://github.com/teddylee777/langchain-kr', 'content': 'GitHub - teddylee777/langchain-kr: LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ğŸŒŸ LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ğŸ”¥ì„±ëŠ¥ì´ ë†€ë¼ì›Œìš”ğŸ”¥ ë¬´ë£Œë¡œ í•œêµ­ì–´ğŸ‡°ğŸ‡· íŒŒì¸íŠœë‹ ëª¨ë¸ ë°›ì•„ì„œ ë‚˜ë§Œì˜ ë¡œì»¬ LLM í˜¸ìŠ¤íŒ… í•˜ê¸°(#LangServe) + #RAG ê¹Œì§€!! ë¬´ë£Œë¡œ í•œêµ­ì–´ğŸ‡°ğŸ‡· íŒŒì¸íŠœë‹ ëª¨ë¸ ë°›ì•„ì„œ ë‚˜ë§Œì˜ ë¡œì»¬ LLM í˜¸ìŠ¤íŒ… í•˜ê¸°(LangServe) + RAG ê¹Œì§€!! ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. langchain-ai ğŸ“– LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python', 'score': 0.3684744, 'raw_content': 'GitHub - teddylee777/langchain-kr: LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nteddylee777 / langchain-kr Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 407\\nStar 1.4k\\n\\nLangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nwikidocs.net/book/14314\\nLicense\\nApache-2.0 license\\n1.4k stars 407 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 2\\nPull requests 0\\nActions\\nProjects 0\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\n\\nteddylee777/langchain-kr\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n391 Commits\\n\\n|\\n| \\n01-Basic\\n| \\n01-Basic\\n| \\n| \\n|\\n| \\n02-Prompt\\n| \\n02-Prompt\\n| \\n| \\n|\\n| \\n03-OutputParser\\n| \\n03-OutputParser\\n| \\n| \\n|\\n| \\n04-Model\\n| \\n04-Model\\n| \\n| \\n|\\n| \\n05-Memory\\n| \\n05-Memory\\n| \\n| \\n|\\n| \\n06-DocumentLoader\\n| \\n06-DocumentLoader\\n| \\n| \\n|\\n| \\n07-TextSplitter\\n| \\n07-TextSplitter\\n| \\n| \\n|\\n| \\n08-Embeddings\\n| \\n08-Embeddings\\n| \\n| \\n|\\n| \\n09-VectorStore\\n| \\n09-VectorStore\\n| \\n| \\n|\\n| \\n10-Retriever\\n| \\n10-Retriever\\n| \\n| \\n|\\n| \\n11-Reranker\\n| \\n11-Reranker\\n| \\n| \\n|\\n| \\n12-RAG\\n| \\n12-RAG\\n| \\n| \\n|\\n| \\n13-LangChain-Expression-Language\\n| \\n13-LangChain-Expression-Language\\n| \\n| \\n|\\n| \\n14-Chains\\n| \\n14-Chains\\n| \\n| \\n|\\n| \\n15-Agent\\n| \\n15-Agent\\n| \\n| \\n|\\n| \\n16-Evaluations\\n| \\n16-Evaluations\\n| \\n| \\n|\\n| \\n17-LangGraph\\n| \\n17-LangGraph\\n| \\n| \\n|\\n| \\n18-FineTuning\\n| \\n18-FineTuning\\n| \\n| \\n|\\n| \\n19-Streamlit\\n| \\n19-Streamlit\\n| \\n| \\n|\\n| \\n20-Projects/01-ParsingOutput\\n| \\n20-Projects/01-ParsingOutput\\n| \\n| \\n|\\n| \\n22-OpenAI\\n| \\n22-OpenAI\\n| \\n| \\n|\\n| \\n99-Projects\\n| \\n99-Projects\\n| \\n| \\n|\\n| \\nimages\\n| \\nimages\\n| \\n| \\n|\\n| \\n.env_sample\\n| \\n.env_sample\\n| \\n| \\n|\\n| \\n.gitignore\\n| \\n.gitignore\\n| \\n| \\n|\\n| \\nLICENSE\\n| \\nLICENSE\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\npoetry.lock\\n| \\npoetry.lock\\n| \\n| \\n|\\n| \\npyproject.toml\\n| \\npyproject.toml\\n| \\n| \\n|\\n| \\nrequirements-mini.txt\\n| \\nrequirements-mini.txt\\n| \\n| \\n|\\n| \\nrequirements-onnx.txt\\n| \\nrequirements-onnx.txt\\n| \\n| \\n|\\n| \\nrequirements.txt\\n| \\nrequirements.txt\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\nApache-2.0 license\\n\\nğŸ“˜ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼\\n\\n\\nğŸŒŸ LangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤.\\në³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nğŸ“” ìœ„í‚¤ë…ìŠ¤ ì „ìì±…(ë¬´ë£Œ)\\n\\n\\nìœ„í‚¤ë…ìŠ¤ì— ë¬´ë£Œ ì „ìì±…ì„ ë“±ë¡í•˜ì˜€ìŠµë‹ˆë‹¤âœŒï¸\\nìœ„í‚¤ë…ìŠ¤ í˜ì´ì§€ì—ì„œ ì±… \"ì¶”ì²œ\" ë²„íŠ¼ í•œ ë²ˆì”©ë§Œ ëˆŒëŸ¬ ì£¼ì‹œë©´ ì œì‘ì— í° í˜ì´ ë©ë‹ˆë‹¤. ë¯¸ë¦¬ ê°ì‚¬ ë“œë¦½ë‹ˆë‹¤ğŸ«¶\\ní‹ˆë‚˜ëŠ”ëŒ€ë¡œ ì—´ì‹¬íˆ ì—…ë°ì´íŠ¸ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œë„ ì‹ ê·œ ê¸°ëŠ¥ì´ ì¶”ê°€ ë  ë•Œë§ˆë‹¤ ë¹ ë¥´ê²Œ x100 ì—…ë°ì´íŠ¸ ì˜ˆì •ì…ë‹ˆë‹¤.\\n\\në­ì²´ì¸LangChain ë…¸íŠ¸ by í…Œë””ë…¸íŠ¸ êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°\\n\\nğŸ¿ ìœ íŠœë¸Œ\\n\\n\\nğŸ¤— huggingface ì— ê³µê°œëœ ì˜¤í”ˆëª¨ë¸ì„ ğŸ’» ë¡œì»¬PC ì—ì„œ ë¹ ë¥´ê²Œ ì‹¤í–‰ğŸ”¥ í•´ë³´ê³  í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë°©ë²• + ëª¨ë¸ ì„œë¹™ğŸš€ + ì—…ë¬´ìë™í™”ğŸ¤– ì— ì ìš©í•˜ëŠ” ë°©ë²•ê¹Œì§€!\\nğŸ‘€ ì½”ë“œ ê¸°ë°˜ ë‹µë³€í•˜ëŠ” ğŸ’» GitHub ì†ŒìŠ¤ì½”ë“œ ê¸°ë°˜ Q&A ì±—ë´‡ğŸ¤– ì œì‘ê¸°\\nllama3 ì¶œì‹œğŸ”¥ ë¡œì»¬ì—ì„œ Llama3-8B ëª¨ë¸ ëŒë ¤ë³´ê¸°ğŸ‘€\\nğŸ”¥ì„±ëŠ¥ì´ ë†€ë¼ì›Œìš”ğŸ”¥ ë¬´ë£Œë¡œ í•œêµ­ì–´ğŸ‡°ğŸ‡· íŒŒì¸íŠœë‹ ëª¨ë¸ ë°›ì•„ì„œ ë‚˜ë§Œì˜ ë¡œì»¬ LLM í˜¸ìŠ¤íŒ… í•˜ê¸°(#LangServe) + #RAG ê¹Œì§€!!\\në¬´ë£Œë¡œ í•œêµ­ì–´ğŸ‡°ğŸ‡· íŒŒì¸íŠœë‹ ëª¨ë¸ ë°›ì•„ì„œ ë‚˜ë§Œì˜ ë¡œì»¬ LLM í˜¸ìŠ¤íŒ… í•˜ê¸°(LangServe) + RAG ê¹Œì§€!!\\nStreamlit ìœ¼ë¡œ ChatGPT í´ë¡  ì„œë¹„ìŠ¤ ì œì‘í•˜ëŠ” ë°©ë²•\\nëŒ€í™”ë‚´ìš©ì„ ê¸°ë¡í•˜ëŠ” LLM Chain ìƒì„± ë°©ë²• + ë„íë¨¼íŠ¸ ì°¸ì¡°í•˜ëŠ” tip!\\n(Self Learning GPT) LangSmith í”¼ë“œë°±ìœ¼ë¡œ ì›í•˜ëŠ” í˜•ì‹ì˜ ë‹µë³€ì„ í•™ìŠµí•˜ëŠ” GPT\\n(LangServe ë¦¬ë·°) ì´ˆê°„í¸ LLM ì›¹ì•± ì œì‘ & ë°°í¬ê¸°ëŠ¥ê¹Œì§€! ê³¼ì—°, Streamlit ëŒ€ì²´í•  ìˆ˜ ìˆì„ê¹Œ?\\nAI vs AI ì˜ëŒ€ ì¦ì›ì— ëŒ€í•œ ëª¨ì˜ ì°¬ë°˜í† ë¡  (AI ë”ë¹™ë³¸)\\ní† ë¡  AI ì—ì´ì „íŠ¸ - ì˜ëŒ€ ì…í•™ì •ì› ì¦ì›ì— ëŒ€í•œ ì°¬ë°˜í† ë¡ ì„ AI ë¼ë¦¬ í•œë‹¤ë©´?\\nê¸´ ë¬¸ì„œ(long context) ì— ëŒ€í•œ ì°¸ì‹ í•œ RAG ë°©ë²•ë¡ : RAPTOR! ë…¼ë¬¸ ë¦¬ë·°ì™€ ì½”ë“œë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤\\nLangChain ë°‹ì—… ë°œí‘œ / R.A.G. ìš°ë¦¬ê°€ ì ˆëŒ€ ì‰½ê²Œê²°ê³¼ë¬¼ì„ ì–»ì„ ìˆ˜ ì—†ëŠ” ì´ìœ \\në…¸ì½”ë”©ìœ¼ë¡œ ì‡¼í•‘ëª° ë¦¬ë·° ë¶„ì„ (í¬ë¡¤ë§ + Q&A ì±—ë´‡)\\nChatGPT ì˜ GPTS ì— API í˜¸ì¶œê¸°ëŠ¥ì„ ë¶™ì´ë©´ ì–´ë–»ê²Œ ë ê¹Œ?\\nLangChain Agent ë¥¼ í™œìš©í•˜ì—¬ ChatGPTë¥¼ ì—…ë¬´ìë™í™” ì— ì ìš©í•˜ëŠ” ë°©ë²•ğŸ”¥ğŸ”¥\\nPrivate GPT! ë‚˜ë§Œì˜ ChatGPT ë§Œë“¤ê¸° (HuggingFace Open LLM í™œìš©)\\nLangGraph ì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì½œë¼ë³´ë ˆì´ì…˜ ì°ë¨¹í•˜ê¸°\\në§ˆë²•ê°™ì€ ë¬¸ë²• LangChain Expression Language(LCEL)\\nì´ë¯¸ì§€ë¥¼ matplotlib íŒŒì´ì¬ ì½”ë“œë¡œ, ì›í•˜ëŠ” ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ íŒŒì´ì¬ ì½”ë“œë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•\\nRAG íŒŒì´í”„ë¼ì¸ ì´í•´í•´ë³´ê¸° - ë„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ ê¸°ë°˜ Q&A ì±—ë´‡ ì œì‘\\nOpenAI ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ Assistant API ì™„ë²½íˆ ì´í•´í•´ë³´ê¸°\\nOpenAI ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ Assistant API 3ê°€ì§€ ë„êµ¬ í™œìš©ë²•\\n\\nâœï¸ ë¸”ë¡œê·¸ ê¸€ ëª©ë¡\\n\\nGeneral\\n\\n\\nOpenAI API ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ / ìš”ê¸ˆí‘œ\\n\\nOpenAI Python API\\n\\n\\nOpenAI Python API í‚¤ ë°œê¸‰ë°©ë²•, ìš”ê¸ˆì²´ê³„\\nì±„íŒ…(chat) í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸°(1)\\nDALLÂ·Eë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±, ìˆ˜ì •, ë‹¤ì–‘í™”í•˜ê¸°(2)\\nWhisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ TTS, STT êµ¬í˜„í•˜ê¸°(3)\\n\\nLangChain\\n\\n\\nOpenAI GPT ëª¨ë¸(ChatOpenAI) ì‚¬ìš©ë²•\\ní—ˆê¹…í˜ì´ìŠ¤(HuggingFace) ëª¨ë¸ ì‚¬ìš©ë²•\\nì±—(chat) - ConversationChain, í…œí”Œë¦¿ ì‚¬ìš©ë²•\\nì •í˜•ë°ì´í„°(CSV, Excel) - ChatGPT ê¸°ë°˜ ë°ì´í„°ë¶„ì„\\nì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ - ì›¹ì‚¬ì´íŠ¸ ë¬¸ì„œ ìš”ì•½\\nì›¹ì‚¬ì´íŠ¸ ì •ë³´ ì¶”ì¶œ - ìŠ¤í‚¤ë§ˆ í™œìš©ë²•\\nPDF ë¬¸ì„œìš”ì•½, Map-Reduce\\nPDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ(Question-Answering)\\në¬¸ì¥ì„ íŒŒì´ì¬ ì½”ë“œë¡œ, ì´ë¯¸ì§€ë¥¼ íŒŒì´ì¬ ì½”ë“œë¡œ ë³€ê²½í•˜ëŠ” ë°©ë²•\\nLangChain Expression Language(LCEL) ì›ë¦¬ ì´í•´ì™€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê°€ì´ë“œ\\nLLMsë¥¼ í™œìš©í•œ ë¬¸ì„œ ìš”ì•½ ê°€ì´ë“œ: Stuff, Map-Reduce, Refine ë°©ë²• ì´ì •ë¦¬\\nìë™í™”ëœ ë©”íƒ€ë°ì´í„° íƒœê¹…ìœ¼ë¡œ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°(metadata) ìƒì„± ë° ìë™ ë¼ë²¨ë§\\në„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ë°˜ Q&A ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•í•˜ê¸° - ê¸°ë³¸í¸\\nRAG íŒŒí—¤ì¹˜ê¸°: ë¬¸ì„œ ê¸°ë°˜ QA ì‹œìŠ¤í…œ ì„¤ê³„ ë°©ë²• - ì‹¬í™”í¸\\nì—ì´ì „íŠ¸(Agent)ì™€ ë„êµ¬(tools)ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ\\n\\nLangGraph\\n\\n\\nMulti-Agent Collaboration(ë‹¤ì¤‘ í˜‘ì—… ì—ì´ì „íŠ¸) ë¡œ ë³µì¡í•œ í…ŒìŠ¤í¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” LLM ì–´í”Œë¦¬ì¼€ì´ì…˜ ì œì‘\\nLangGraph Retrieval Agentë¥¼ í™œìš©í•œ ë™ì  ë¬¸ì„œ ê²€ìƒ‰ ë° ì²˜ë¦¬\\n\\nğŸ‘¥ LangChain ë°‹ì—… 2024 Q1 ë°œí‘œìë£Œ\\n\\n\\nRAG - ìš°ë¦¬ê°€ ì ˆëŒ€ ì‰½ê²Œ ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì„ ì–»ì„ ìˆ˜ ì—†ëŠ” ì´ìœ  - í…Œë””ë…¸íŠ¸\\ní”„ë¦„í”„íŠ¸ íë¦„ê³¼ LLM ëª¨ë¸ í‰ê°€ - ì´ì¬ì„ë‹˜\\nì¸ê³µì§€ëŠ¥ì„ í†µí•œ ê²Œì„ ì œì‘ íŒŒì´í”„ë¼ì¸ì˜ ë³€í™” - ê¹€í•œì–¼ë‹˜\\nOpenAI SORA ì‚´ì§ ë§›ë³´ê¸° - ë°•ì •í˜„ë‹˜\\nSemantic Kernelë¡œ ë§Œë“œëŠ” AI Copilot - ì´ì¢…ì¸ë‹˜\\nStreamlit ê³¼ langchainìœ¼ë¡œ ë‚˜ë§Œì˜ ì›¹ì„œë¹„ìŠ¤ ê°œë°œí•˜ê¸° - ìµœì¬í˜ë‹˜\\nLlama2-koenì„ ë§Œë“¤ê¸°ê¹Œì§€ - ìµœíƒœê· ë‹˜\\nì˜¬ë°”ë¥¸ í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•´: HAE-RAE Bench, KMMLU - ì†ê·œì§„ë‹˜\\në­ì²´ì¸ ë„¤ì´ë²„ ê¸°ì‚¬ í¬ë¡¤ë§ - ìš°ì„±ìš°ë‹˜\\nGemmaì™€ LangChainì„ ì´ìš©í•œ SQL ì²´ì¸ë§Œë“¤ê¸° - ê¹€íƒœì˜ë‹˜\\n\\nğŸ“œ ë¼ì´ì„ ìŠ¤\\n\\në³¸ í”„ë¡œì íŠ¸ëŠ” Apache License 2.0ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.\\nğŸš« ë¼ì´ì„ ìŠ¤ ê³ ì§€\\n\\nğŸ”’ ë³¸ ë‚´ìš©ì˜ ì €ì‘ê¶Œì€ 2024ë…„ í…Œë””ë…¸íŠ¸ì— ìˆìŠµë‹ˆë‹¤. ëª¨ë“  ê¶Œë¦¬ëŠ” ì €ì‘ê¶Œìì—ê²Œ ìˆìœ¼ë©°, teddylee777@gmail.com ìœ¼ë¡œ ë¬¸ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n```\\nCopyright 2024 í…Œë””ë…¸íŠ¸(teddylee777@gmail.com)\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n```\\nì¸ìš© ë° ì¶œì²˜ í‘œê¸°\\n\\në³¸ ì €ì‘ë¬¼ì˜ ë‚´ìš©ì„ ë¸”ë¡œê·¸, ìœ íŠœë¸Œ ë“± ì˜¨ë¼ì¸ ë§¤ì²´ì— ì¸ìš©í•˜ì—¬ ê²Œì¬í•˜ëŠ” ê²½ìš°, ì €ì‘ê¶Œë²•ì— ë”°ë¼ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œ í•´ì•¼ í•©ë‹ˆë‹¤.\\n\\nìƒì—…ì  ì‚¬ìš©ì— ëŒ€í•œ ì‚¬ì „ í˜‘ì˜\\n\\në³¸ ì €ì‘ë¬¼(Wikidocs ë° ê´€ë ¨ ì‹¤ìŠµ ì½”ë“œ í¬í•¨)ì„ ê°•ì˜, ê°•ì—° ë“± ìƒì—…ì  ëª©ì ìœ¼ë¡œ í™œìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš°, ì €ì‘ê¶Œìì™€ì˜ ì‚¬ì „ ì„œë©´ í˜‘ì˜ê°€ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬ë©ë‹ˆë‹¤.\\n\\në³¸ ë‚´ìš©ì˜ ë¬´ë‹¨ ì „ì¬ ë° ì¬ë°°í¬ë¥¼ ê¸ˆì§€í•©ë‹ˆë‹¤. ë³¸ ë‚´ìš©ì˜ ì „ì²´ í˜¹ì€ ì¼ë¶€ë¥¼ ì¸ìš©í•  ê²½ìš°, ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°í˜€ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ë³¸ ë¬¸ì„œëŠ” ë‹¤ë¥¸ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£ŒëŠ” ë³¸ ë¬¸ì„œ í•˜ë‹¨ì˜ ì¶œì²˜ ëª©ë¡ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nğŸ“š ì¶œì²˜\\n\\n\\nlangchain-ai ğŸ“–\\nOpenAI API Reference ğŸ¤–\\n\\nğŸŒ ì¶”ê°€ ìë£Œ\\n\\n\\nìœ íŠœë¸Œ ì±„ë„: LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ğŸ¥\\në¸”ë¡œê·¸: í…Œë””ë…¸íŠ¸ ğŸ“\\nPlayground: LangChain LLM Playground ğŸ®\\n\\nğŸš€ ì‹œì‘í•˜ê¸°\\n\\në³¸ íŠœí† ë¦¬ì–¼ì„ ì‹œì‘í•˜ê¸° ì „ì—, LangChainê³¼ ê´€ë ¨ëœ ê¸°ë³¸ì ì¸ ì§€ì‹ì„ ê°–ì¶”ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ìœ„ì˜ ì¶œì²˜ ë§í¬ë¥¼ í†µí•´ ê¸°ë³¸ì ì¸ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nStart History\\n\\n\\nğŸ’¡ ì»¨íŠ¸ë¦¬ë·°ì…˜\\n\\në³¸ íŠœí† ë¦¬ì–¼ì— ê¸°ì—¬í•˜ê³ ì í•˜ëŠ” ë¶„ë“¤ì€ ì–¸ì œë“ ì§€ í’€ ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ì£¼ì‹œê±°ë‚˜, ì´ìŠˆë¥¼ ë“±ë¡í•˜ì—¬ ì˜ê²¬ì„ ê³µìœ í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ëª¨ë“  ê¸°ì—¬ëŠ” ë³¸ í”„ë¡œì íŠ¸ì˜ ë°œì „ì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤. ğŸ’–\\n\\nAbout\\nLangChain ê³µì‹ Document, Cookbook, ê·¸ ë°–ì˜ ì‹¤ìš© ì˜ˆì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤. ë³¸ íŠœí† ë¦¬ì–¼ì„ í†µí•´ LangChainì„ ë” ì‰½ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\nwikidocs.net/book/14314\\nTopics\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\nResources\\nReadme\\nLicense\\nApache-2.0 license\\nActivity\\nStars\\n1.4k stars\\nWatchers\\n37 watching\\nForks\\n407 forks\\nReport repository\\nReleases\\nNo releases published\\nPackages 0\\nNo packages published  \\nContributors 5\\nLanguages\\n\\nJupyter Notebook 97.8%\\nPython 2.0%\\nHTML 0.2%\\n\\nFooter\\nÂ© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou canâ€™t perform that action at this time.'}]\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ\n",
    "result = web_search_tool.search(\"í…Œë””ë…¸íŠ¸ ìœ„í‚¤ë…ìŠ¤ ë­ì²´ì¸ íŠœí† ë¦¬ì–¼ URL ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1904c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'linktr.ee/teddynote | Linktree',\n",
       " 'url': 'https://linktr.ee/teddynote',\n",
       " 'content': '03/04 LangGraph Hands On íŠœí† ë¦¬ì–¼ (2ì‹œê°„ ë¶„ëŸ‰) [FastCampus] í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸ğŸ™Œ. ğŸ”¥[100% ë¬´ë£Œ] í…Œë””ë…¸íŠ¸ YouTube ì½˜í…ì¸  í•™ìŠµ ìˆœì„œğŸ”¥. ğŸ“˜ ë­ì²´ì¸ í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· ... Github. 9/21 í…Œë””ë…¸íŠ¸-Gencon2024-ModularRAG-20240921.pdf.',\n",
       " 'score': 0.6072213,\n",
       " 'raw_content': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ê²°ê³¼ì˜ ì²« ë²ˆì§¸ ê²°ê³¼ í™•ì¸\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac37855",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab91c2",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d23ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ì˜ ìƒíƒœ ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° ëª¨ë¸\n",
    "\n",
    "    Attributes:\n",
    "        question: ì§ˆë¬¸\n",
    "        generation: LLM ìƒì„±ëœ ë‹µë³€\n",
    "        documents: ë„íë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266cc42",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ íë¦„ ì •ì˜\n",
    "\n",
    "**ê·¸ë˜í”„ íë¦„**ì„ ì •ì˜í•˜ì—¬ **Adaptive RAG**ì˜ ì‘ë™ ë°©ì‹ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ê·¸ë˜í”„ì˜ ìƒíƒœì™€ ì „í™˜ì„ ì„¤ì •í•˜ì—¬ ì¿¼ë¦¬ ì²˜ë¦¬ì˜ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
    "\n",
    "- **ìƒíƒœ ì •ì˜**: ê·¸ë˜í”„ì˜ ê° ìƒíƒœë¥¼ ëª…í™•íˆ ì •ì˜í•˜ì—¬ ì¿¼ë¦¬ì˜ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "- **ì „í™˜ ì„¤ì •**: ìƒíƒœ ê°„ì˜ ì „í™˜ì„ ì„¤ì •í•˜ì—¬ ì¿¼ë¦¬ê°€ ì ì ˆí•œ ê²½ë¡œë¥¼ ë”°ë¼ ì§„í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- **íë¦„ ìµœì í™”**: ê·¸ë˜í”„ì˜ íë¦„ì„ ìµœì í™”í•˜ì—¬ ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ ì •í™•ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bf00c",
   "metadata": {},
   "source": [
    "### ë…¸ë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee6f34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG ë‹µë³€ ìƒì„±\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ê° ë¬¸ì„œì— ëŒ€í•œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # ê´€ë ¨ì„±ì´ ìˆëŠ” ë¬¸ì„œ ì¶”ê°€\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # ê´€ë ¨ì„±ì´ ì—†ëŠ” ë¬¸ì„œëŠ” ê±´ë„ˆë›°ê¸°\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs}\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ ì¬ì‘ì„± ë…¸ë“œ\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec62cc",
   "metadata": {},
   "source": [
    "## ì¶”ê°€ ë…¸ë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d33976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ë¼ìš°íŒ… ë…¸ë“œ\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    # ì§ˆë¬¸ ë¼ìš°íŒ…\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # ì§ˆë¬¸ ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¥¸ ë…¸ë“œ ë¼ìš°íŒ…\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ë…¸ë“œ\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # ëª¨ë“  ë¬¸ì„œê°€ ê´€ë ¨ì„± ì—†ëŠ” ê²½ìš° ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° ë‹µë³€ ìƒì„±\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # í™˜ê° í‰ê°€\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination ì—¬ë¶€ í™•ì¸\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # ë‹µë³€ì˜ ê´€ë ¨ì„±(Relevance) í‰ê°€\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # ê´€ë ¨ì„± í‰ê°€ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412119d",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "\n",
    "**ê·¸ë˜í”„ ì»´íŒŒì¼** ë‹¨ê³„ì—ì„œëŠ” **Adaptive RAG**ì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒíƒœë¡œ ë§Œë“­ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ê·¸ë˜í”„ì˜ ê° ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì—°ê²°í•˜ì—¬ ì¿¼ë¦¬ ì²˜ë¦¬ì˜ ì „ì²´ íë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ë…¸ë“œ ì •ì˜**: ê° ë…¸ë“œë¥¼ ì •ì˜í•˜ì—¬ ê·¸ë˜í”„ì˜ ìƒíƒœì™€ ì „í™˜ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.\n",
    "- **ì—£ì§€ ì„¤ì •**: ë…¸ë“œ ê°„ì˜ ì—£ì§€ë¥¼ ì„¤ì •í•˜ì—¬ ì¿¼ë¦¬ê°€ ì ì ˆí•œ ê²½ë¡œë¥¼ ë”°ë¼ ì§„í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- **ì›Œí¬í”Œë¡œìš° êµ¬ì¶•**: ê·¸ë˜í”„ì˜ ì „ì²´ íë¦„ì„ êµ¬ì¶•í•˜ì—¬ ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c106a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒíƒœ ì´ˆê¸°í™”\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ë…¸ë“œ ì •ì˜\n",
    "workflow.add_node(\"web_search\", web_search)  # ì›¹ ê²€ìƒ‰\n",
    "workflow.add_node(\"retrieve\", retrieve)  # ë¬¸ì„œ ê²€ìƒ‰\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # ë¬¸ì„œ í‰ê°€\n",
    "workflow.add_node(\"generate\", generate)  # ë‹µë³€ ìƒì„±\n",
    "workflow.add_node(\"transform_query\", transform_query)  # ì¿¼ë¦¬ ë³€í™˜\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë“œ\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",  # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë¼ìš°íŒ…\n",
    "        \"vectorstore\": \"retrieve\",  # ë²¡í„°ìŠ¤í† ì–´ë¡œ ë¼ìš°íŒ…\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")  # ì›¹ ê²€ìƒ‰ í›„ ë‹µë³€ ìƒì„±\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")  # ë¬¸ì„œ ê²€ìƒ‰ í›„ í‰ê°€\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # ì¿¼ë¦¬ ë³€í™˜ í•„ìš”\n",
    "        \"generate\": \"generate\",  # ë‹µë³€ ìƒì„± ê°€ëŠ¥\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")  # ì¿¼ë¦¬ ë³€í™˜ í›„ ë¬¸ì„œ ê²€ìƒ‰\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    hallucination_check,\n",
    "    {\n",
    "        \"hallucination\": \"generate\",  # Hallucination ë°œìƒ ì‹œ ì¬ìƒì„±\n",
    "        \"relevant\": END,  # ë‹µë³€ì˜ ê´€ë ¨ì„± ì—¬ë¶€ í†µê³¼\n",
    "        \"not relevant\": \"transform_query\",  # ë‹µë³€ì˜ ê´€ë ¨ì„± ì—¬ë¶€ í†µê³¼ ì‹¤íŒ¨ ì‹œ ì¿¼ë¦¬ ë³€í™˜\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f4505",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ ì‹œê°í™” í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2739b",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‚¬ìš©\n",
    "\n",
    "**ê·¸ë˜í”„ ì‚¬ìš©** ë‹¨ê³„ì—ì„œëŠ” **Adaptive RAG**ì˜ ì‹¤í–‰ì„ í†µí•´ ì¿¼ë¦¬ ì²˜ë¦¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ê·¸ë˜í”„ì˜ ê° ë…¸ë“œì™€ ì—£ì§€ë¥¼ ë”°ë¼ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ê·¸ë˜í”„ ì‹¤í–‰**: ì •ì˜ëœ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¿¼ë¦¬ì˜ íë¦„ì„ ë”°ë¼ê°‘ë‹ˆë‹¤.\n",
    "- **ê²°ê³¼ í™•ì¸**: ê·¸ë˜í”„ ì‹¤í–‰ í›„ ìƒì„±ëœ ê²°ê³¼ë¥¼ ê²€í† í•˜ì—¬ ì¿¼ë¦¬ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "- **ê²°ê³¼ ë¶„ì„**: ìƒì„±ëœ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì¿¼ë¦¬ì˜ ëª©ì ì— ë¶€í•©í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\n",
    "    \"question\": \"í˜„ì—­ì„ ìˆ˜ë“±ë¡ì€ ëª‡ëª…ì´ì•¼?\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = {\n",
    "    \"question\": \"2024ë…„ ë…¸ë²¨ ë¬¸í•™ìƒ ìˆ˜ìƒìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
