import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import ChatMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

load_dotenv()

### ì‹¤í–‰: streamlit run main.py

if "messages" not in st.session_state:
    st.session_state["messages"] = []

st.title("YJNOH ChatGPTğŸ¥³")
st.markdown(
    """
    <style>
    /* ì „ì²´ ë°°ê²½ìƒ‰ */
    .stApp {
        background-color: #ECEFF1;
        color: #37474F;
    }

    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    [data-testid="stSidebar"] {
        background: #CFD8DC;
        border-right: 3px solid #B0BEC5;
    }

    /* ì‚¬ì´ë“œë°” ë‚´ë¶€ í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    [data-testid="stSidebar"] * {
        color: #37474F;
    }

    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton>button {
        background-color: #607D8B;
        color: white;
        border-radius: 8px;
        padding: 10px 18px;
    }

    /* ë²„íŠ¼ í˜¸ë²„ íš¨ê³¼ */
    .stButton>button:hover {
        background-color: #546E7A;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

with st.sidebar:
    btn_reset = st.button("ëŒ€í™” ì´ˆê¸°í™”")

    selected_model = st.selectbox(
        "GPT ëª¨ë¸",
        ("gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"),
        index=0,
        placeholder="ëª¨ë¸ ì„ íƒí•˜ê¸°",
    )

    system_prompt = st.text_input(
        "System Prompt ì…ë ¥", "ë‹¹ì‹ ì€ í™”ê°€ë‚œ AI Assistant ì…ë‹ˆë‹¤."
    )

user_input = st.chat_input("ê¶ê¸ˆí•œê²ƒì„ ì…ë ¥í•˜ì„¸ìš”")


def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


if btn_reset:
    st.session_state["messages"] = []

print_messages()


def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


if user_input:
    st.chat_message("user").write(user_input)

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("user", "#question\n{question}"),
        ]
    )

    llm = ChatOpenAI(model_name=selected_model, temperature=0)
    output_parser = StrOutputParser()

    # chain
    chain = prompt | llm | output_parser
    ai_answer = chain.stream({"question": user_input})

    with st.chat_message("assistant"):
        container = st.empty()
        answer = ""
        for token in ai_answer:
            answer += token
            container.write(answer)

    add_message(role="user", message=user_input)
    add_message(role="assistant", message=answer)
